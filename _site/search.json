[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there! Welcome to my ISSS608 Visual Analytics homepage!\nI’m Sei Sar, a Master of IT in Business student at SMU. This website highlights my journey in learning Visual Analytics under the guidance of Professor Kam Tim Seong. The course features Hands-on Exercises, In-class Exercises, and Take Home Assignments that provide practical experience and deepen my understanding of this exciting new field that I am exploring. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Homepage",
    "section": "",
    "text": "Hi there! Welcome to my ISSS608 Visual Analytics homepage!\n\n\n\n\n\nI’m Sei Sar, a Master of IT in Business student at SMU. This website highlights my journey in learning Visual Analytics under the guidance of Professor Kam Tim Seong. The course features Hands-on Exercises, In-class Exercises, and Take Home Assignments that provide practical experience and deepen my understanding of this exciting new field that I am exploring. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands-on Exercise 01",
    "section": "4 R Graphics VS ggplot",
    "text": "4 R Graphics VS ggplot\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy ggplot2 is recommended?\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "A Layered Grammar of Graphics",
    "text": "A Layered Grammar of Graphics\n\n\n\n\n\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.1 data",
    "text": "5.1 data\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#aesthetic-mappings",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.2 Aesthetic mappings",
    "text": "5.2 Aesthetic mappings\nAll aesthetics of a plot are specified in the aes() function call\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geom",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.3 geom",
    "text": "5.3 geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\ngeom_bargeom_dotplotgeom_histogram\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\nThe y scale is very misleading.\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n5.3.1 Modifying geometric object\n\nModifying a geometric object by changing geom()Modifying a geometric object by changing aes()\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below changes the interior colour of the histogram by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.2 Geometric Objects\n\ngeom_densitygeom_boxplotgeom_violingeom_point\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 geom objects can be combined\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#stat",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.4 stat",
    "text": "5.4 stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n5.4.1 stat()\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplots below are incomplete because the positions of the means were not shown.\n\n\n5.4.2 stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n5.4.3 geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n5.4.4 Adding a best fit curve on a scatterplot?\n\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#facets",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.5 Facets",
    "text": "5.5 Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n5.5.1 facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n5.5.2 facet_grid()\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#coordinates",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.6 Coordinates",
    "text": "5.6 Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped.\n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot).\n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n5.6.1 Working with Coordinate\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.The code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n5.6.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#themes",
    "title": "Hands-on Exercise 01: A Layered Grammar of Graphics: ggplot2 methods",
    "section": "5.7 Themes",
    "text": "5.7 Themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\ntheme_graytheme_classictheme_minimal\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "CodeExplanation\n\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "4.1 Working with ggtheme package",
    "text": "4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_solarized()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe solarized theme is used here."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthems-package",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "4.2 Working with hrbthems package",
    "text": "4.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\nAdd in the following three:\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.1 Creating Composite Graphics: pathwork methods",
    "text": "5.1 Creating Composite Graphics: pathwork methods\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package.\nThere is a ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n5.1.1 Combining two ggplot2 graphs\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n5.1.2 Combining three ggplot2 graphs\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n5.1.3 Creating a composite figure with tag\n\nplot_annotation() is used to add labels, titles, captions, and other metadata to the combined plot.\nThe argument tag_levels = 'I' automatically tags the individual subplots with Roman numerals (e.g., I, II, III).\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n5.1.4 Creating figure with insert\nWith inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n5.1.5 Creating a composite figure by using patchwork and ggtheme\nPutting what we learned through this exercise all together:\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_solarized()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "1 Installing and Loading Packages\n\npacman::p_load(tidyverse)\n\n\n\n2 Importing Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.1 Combining two ggplot2 graphs",
    "text": "5.1 Combining two ggplot2 graphs\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.2 Combining three ggplot2 graphs",
    "text": "5.2 Combining three ggplot2 graphs\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.3 Creating a composite figure with tag",
    "text": "5.3 Creating a composite figure with tag\n\nplot_annotation() is used to add labels, titles, captions, and other metadata to the combined plot.\nThe argument tag_levels = 'I' automatically tags the individual subplots with Roman numerals (e.g., I, II, III).\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.4 Creating figure with insert",
    "text": "5.4 Creating figure with insert\nWith inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "5.5 Creating a composite figure by using patchwork and ggtheme",
    "text": "5.5 Creating a composite figure by using patchwork and ggtheme\nPutting what we learned through this exercise all together:\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_solarized()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "Explanation of PackagesCode\n\n\nThe following packages will be installed for this exercise:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\n\n\n\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\n\nExplanation of CodeCode\n\n\nThe code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\nTwo steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\n\n\n\n\n\nNote\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.default value of the hover css is hover_css = “fill:orange;”.\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\nCoordinated multiple views - when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe code chunk below shows a basic interactive scatter plot made from plot_ly\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nColor argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\nExplanation of CodeCode\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data. This simply creates an object of class crosstalk::SharedData\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nExplanationCode\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n\n\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-packages",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "Explanation of PackagesCode\n\n\nThe following packages will be installed for this exercise:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "The code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "ggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\n\nExplanation of CodeCode\n\n\nThe code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\nTwo steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\n\n\n\n\n\nNote\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.default value of the hover css is hover_css = “fill:orange;”.\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\nCoordinated multiple views - when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "There are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe code chunk below shows a basic interactive scatter plot made from plot_ly\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nColor argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\nExplanation of CodeCode\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data. This simply creates an object of class crosstalk::SharedData\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "",
    "text": "Crosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nExplanationCode\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n\n\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#basic-concepts-of-animation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#basic-concepts-of-animation",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "2.1 Basic concepts of animation",
    "text": "2.1 Basic concepts of animation\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\nSome terminology to note:\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nAsk yourself!\n\n\n\nDoes it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-the-r-packages",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "2.2 Installing and Loading the R packages",
    "text": "2.2 Installing and Loading the R packages\n\nPackagesCode\n\n\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "2.3 Importing the data",
    "text": "2.3 Importing the data\n\nExplanationCode\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor. (Since mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0, we will re-write the code by using mutate_at() as shown in the code chunk below.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation---gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation---gganimate-methods",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "2.4 Animated Data Visualisation - gganimate methods",
    "text": "2.4 Animated Data Visualisation - gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n2.4.1 Building a static population bubble plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n2.4.2 Building a animated bubble plot\n\nExplanationCode\n\n\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 03: Programming Interactive Data Visualisation and Animated Statistical Graphics with R",
    "section": "2.5 Animated Data Visualisation - plotly methods",
    "text": "2.5 Animated Data Visualisation - plotly methods\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id.\n\n2.5.1 Building an animated bubble plot: ggplotly() method\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\n2.5.2 Building an animated bubble plot: plotly() method\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "Heart disease remains one of the leading causes of mortality worldwide, and Japan is no exception. Despite the country’s reputation for longevity and a traditionally healthy diet, heart-related health issues—including heart attacks—continue to be a significant public health concern. The impact of heart attacks varies across different age groups, with risk factors and outcomes often differing between younger and older individuals. While Japan’s aging population naturally sees a higher prevalence of heart attacks among adults, recent trends suggest that younger individuals are also increasingly at risk, raising concerns about lifestyle habits and diet.\nHistorically, Japan’s diet—rich in fish, vegetables, and low in saturated fats—has been associated with lower cardiovascular disease rates. However, research by Iso (2011) has highlighted a gradual shift toward Westernized dietary patterns, characterized by increased consumption of meat and processed foods, which has contributed to rising cholesterol levels and a greater risk of heart disease. Additionally, lifestyle factors such as physical inactivity, smoking, and alcohol consumption have played a role in shaping cardiovascular health trends within the country.\nMedical advancements and early interventions have improved survival rates, but the rising burden of cardiovascular diseases still calls for further research and public awareness.\n\n\n\nThis article aims to explore the patterns of heart attacks in Japan across different age groups and shedding light on key factors contributing to their occurrence. By examining trends, potential risk factors, and demographic variations, we seek to provide insights into how heart attack cases differ between youth and adults.\nThrough data-driven visualizations, we will highlight the prevalence, underlying causes, and potential warning signs associated with heart attacks in Japan. The goal is to help healthcare professionals, policymakers, and the general public better understand the evolving landscape of cardiovascular health and to encourage proactive measures for prevention and early detection."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "Heart disease remains one of the leading causes of mortality worldwide, and Japan is no exception. Despite the country’s reputation for longevity and a traditionally healthy diet, heart-related health issues—including heart attacks—continue to be a significant public health concern. The impact of heart attacks varies across different age groups, with risk factors and outcomes often differing between younger and older individuals. While Japan’s aging population naturally sees a higher prevalence of heart attacks among adults, recent trends suggest that younger individuals are also increasingly at risk, raising concerns about lifestyle habits and diet.\nHistorically, Japan’s diet—rich in fish, vegetables, and low in saturated fats—has been associated with lower cardiovascular disease rates. However, research by Iso (2011) has highlighted a gradual shift toward Westernized dietary patterns, characterized by increased consumption of meat and processed foods, which has contributed to rising cholesterol levels and a greater risk of heart disease. Additionally, lifestyle factors such as physical inactivity, smoking, and alcohol consumption have played a role in shaping cardiovascular health trends within the country.\nMedical advancements and early interventions have improved survival rates, but the rising burden of cardiovascular diseases still calls for further research and public awareness."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "This article aims to explore the patterns of heart attacks in Japan across different age groups and shedding light on key factors contributing to their occurrence. By examining trends, potential risk factors, and demographic variations, we seek to provide insights into how heart attack cases differ between youth and adults.\nThrough data-driven visualizations, we will highlight the prevalence, underlying causes, and potential warning signs associated with heart attacks in Japan. The goal is to help healthcare professionals, policymakers, and the general public better understand the evolving landscape of cardiovascular health and to encourage proactive measures for prevention and early detection."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.1 Importing the Data",
    "text": "4.1 Importing the Data\nThe code chunk below imports japan_heart_attack_dataset.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nheartattack_data &lt;- read_csv(\"data/raw/japan_heart_attack_dataset.csv\")\n\nLet’s view the structure of the dataset using glimpse(), which allows us to see data structure and variable names as well as types.\n\nglimpse(heartattack_data)\n\nRows: 30,000\nColumns: 32\n$ Age                     &lt;dbl&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Region                  &lt;chr&gt; \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Rural\", \"…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Hypertension_History    &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Diet_Quality            &lt;chr&gt; \"Poor\", \"Good\", \"Average\", \"Good\", \"Good\", \"Go…\n$ Alcohol_Consumption     &lt;chr&gt; \"Low\", \"Low\", \"Moderate\", \"High\", \"High\", \"Hig…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ Extra_Column_1          &lt;dbl&gt; 0.40498852, 0.03627815, 0.85297888, 0.39085280…\n$ Extra_Column_2          &lt;dbl&gt; 0.43330004, 0.51256694, 0.21959083, 0.29684675…\n$ Extra_Column_3          &lt;dbl&gt; 0.62871236, 0.66839275, 0.61343656, 0.15572404…\n$ Extra_Column_4          &lt;dbl&gt; 0.70160955, 0.11552874, 0.50800995, 0.87025144…\n$ Extra_Column_5          &lt;dbl&gt; 0.49814235, 0.42381938, 0.90066981, 0.39035591…\n$ Extra_Column_6          &lt;dbl&gt; 0.007901312, 0.083932768, 0.227205241, 0.40318…\n$ Extra_Column_7          &lt;dbl&gt; 0.79458257, 0.68895108, 0.49634358, 0.74140891…\n$ Extra_Column_8          &lt;dbl&gt; 0.29077922, 0.83016364, 0.75210679, 0.22396813…\n$ Extra_Column_9          &lt;dbl&gt; 0.49719307, 0.63449028, 0.18150125, 0.32931387…\n$ Extra_Column_10         &lt;dbl&gt; 0.52199452, 0.30204337, 0.62918031, 0.14319054…\n$ Extra_Column_11         &lt;dbl&gt; 0.79965663, 0.04368285, 0.01827617, 0.90778075…\n$ Extra_Column_12         &lt;dbl&gt; 0.72239788, 0.45166789, 0.06322702, 0.54232201…\n$ Extra_Column_13         &lt;dbl&gt; 0.1487387, 0.8786714, 0.1465122, 0.9224606, 0.…\n$ Extra_Column_14         &lt;dbl&gt; 0.8340099, 0.5356022, 0.9972962, 0.6262165, 0.…\n$ Extra_Column_15         &lt;dbl&gt; 0.061632229, 0.617825340, 0.974455410, 0.22860…\n\n\nAt a glimpse, we see that there at 32,000 rows and 32 columns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filtering-for-relevant-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filtering-for-relevant-variables",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.2 Filtering for Relevant Variables",
    "text": "4.2 Filtering for Relevant Variables\nWe notice that there were certain columns titled “Extra_Column_” from column number 18 to 32. We will remove these columns as there are no explanations in the metadata from the source, leaving us with 17 variables to work with.\n\nheartattack_data &lt;- heartattack_data %&gt;% select(-c(18:32))\n\nWe also notice that this dataset also contains data for people with no heart attack occurrence (in the Heart_Attack_Occurrence column). Since we are performing exploratory data analysis (EDA), it would be valuable to keep both groups, as this allows us to identify and compare characteristics like age, gender, lifestyle, or pre-existing conditions between those who had a heart attack and those who didn’t, potentially letting us uncover patterns or trends that can inform the study."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicates-and-missing-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicates-and-missing-values",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.3 Checking for Duplicates and Missing values",
    "text": "4.3 Checking for Duplicates and Missing values\nIt is essential to check for duplicates and missing values before we move forward. We will use the following code to check for them.\n\nChecking for DuplicatesChecking for Missing Values\n\n\nThe duplicated() function in the base package is used to check for duplicates in heartattack_data.\n\nsum(duplicated(heartattack_data))\n\n[1] 0\n\n\n\n\nThe colSums() function in the base package is used to check for missing values in heartattack_data.\n\ncolSums(is.na(heartattack_data))\n\n                    Age                  Gender                  Region \n                      0                       0                       0 \n        Smoking_History        Diabetes_History    Hypertension_History \n                      0                       0                       0 \n      Cholesterol_Level       Physical_Activity            Diet_Quality \n                      0                       0                       0 \n    Alcohol_Consumption           Stress_Levels                     BMI \n                      0                       0                       0 \n             Heart_Rate             Systolic_BP            Diastolic_BP \n                      0                       0                       0 \n         Family_History Heart_Attack_Occurrence \n                      0                       0 \n\n\n\n\n\nWe have confirmed that there are no duplicates and missing values in this dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#grouping-variables-into-categories",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#grouping-variables-into-categories",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.4 Grouping Variables into Categories",
    "text": "4.4 Grouping Variables into Categories\nSome numerical variables (represented as “dbl” when we checked data structure in section 4.1), will be grouped into the following categories for meaningful insights:\n\nAge: For this variable which ranges from 18 to 79, we will use equal bins for each category, categorized as:\n\nYoung: 18–39\nMiddle-Aged: 40–59\nOld: 60–79\n\nStress Level: A common method to measure stress is the Perceived Stress Scale (Cohen,1994) where individuals rate their stress from 0 (no stress) to 10 (extreme stress). Since our dataset uses a 0 to 10 range, it’s likely a self-reported scale, where 0-3 represents minimal or manageable stress, 4-6 represents moderate stress and 7-10 represents high to extreme stress, with potential health risks. Therefore, we will categorize the stress levels as:\n\nLow: 0.000–3.999\nMedium: 4.000–6.999\nHigh: 7.000–10.000\n\n\n\nheartattack_data &lt;- heartattack_data %&gt;%\n  mutate(\n    AgeCat = case_when(\n      Age &gt;= 18 & Age &lt;= 39 ~ \"Young\",\n      Age &gt;= 40 & Age &lt;= 59 ~ \"Middle-Aged\",\n      Age &gt;= 60 & Age &lt;= 79 ~ \"Old\"\n    ),\n    \n    \n    Stress = case_when(\n      Stress_Levels &gt;= 0.000 & Stress_Levels &lt;= 3.999999 ~ \"Low\",\n      Stress_Levels &gt; 4.000 & Stress_Levels &lt;= 6.999999 ~ \"Medium\",\n      Stress_Levels &gt; 7.000 & Stress_Levels &lt;= 10.000 ~ \"High\"\n    )\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#section",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#section",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.5 …",
    "text": "4.5 …\nLastly, save the prepared output to rds format using the following code chunk. We will use this newly prepared data from this point.\n\nSave to .rds formatLoad the rds file\n\n\n\nwrite_rds(heartattack_data, file = \"data/rds/heartattack.rds\")\n\n\n\n\nheartattack &lt;- read_rds(\"data/rds/heartattack.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-analysis-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-analysis-1",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.1 Exploratory Analysis 1:",
    "text": "5.1 Exploratory Analysis 1:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "",
    "text": "Packages UsedCode\n\n\nThe following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\n\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\n\n\n\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n\n\n\n\n\nWhen Ridgeline Plots Make Sense\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe following code chunk is plotted using geom_density_ridges.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nInsights: We see that class 3A has the highest English grades with higher data densities around 80.\nTo use geom_ridgeline() , we will need to explicitly calculate the density for each group (i.e., each CLASS in your example). This is because geom_density_ridges() automatically computes the density for you, whereas geom_ridgeline() requires the density data to be precomputed.\n\nStepsCode\n\n\n\nCompute the density for each group using ggplot2’s ggplot2::stat_density or base R/tidyverse tools.\nUse the computed density values as input to geom_ridgeline().\n\n\n\n\n# Compute density for each class\ndensity_data &lt;- exam %&gt;%\n  group_by(CLASS) %&gt;%\n  summarise(\n    density = list(density(ENGLISH, bw = 3.4)[c(\"x\", \"y\")]),\n    .groups = \"drop\"\n  ) %&gt;%\n  unnest_wider(density) %&gt;%\n  unnest(cols = c(x, y)) %&gt;%\n  mutate(y = y * 15)\n\nfill_color &lt;- alpha(\"#7097BB\", 0.7)\n\n# Create the plot\nggplot(density_data, aes(x = x, y = CLASS, height = y)) +\n  geom_ridgeline(\n    fill = fill_color,\n    color = \"white\",\n    min_height = 0.01\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\nWe can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.This produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0, \n               point_colour = NA) #We remove the slab interval by setting .width = 0 and point_colour = NA\n\n\n\n\n\n\n\n\nInsights: More variations between the English scores are present for Chinese and Malay students which may also be because there are more students for these race.\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\nWe can even add values like median values on top of the boxplots to gain insights at a quick glance as shown in the figure below.\n\nsummary_stats &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(median = median(ENGLISH))\n\nggplot(exam, aes(x = RACE, y = ENGLISH)) +\n  stat_halfeye(\n    adjust = 0.5,\n    justification = -0.2,\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.20,\n    outlier.shape = NA\n  ) +\n  geom_text(\n    data = summary_stats, \n    aes(x = RACE, y = median, label = round(median, 1)), \n    vjust = -1.5, \n    size = 4, \n    color = \"blue\"\n  ) +\n  labs(\n    x = \"RACE\",\n    y = \"ENGLISH\",\n    title = \"Boxplot with Median Values\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "",
    "text": "Packages UsedCode\n\n\nThe following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially desgin for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, an R package provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\n\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "",
    "text": "In the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saved it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n\n\n\n\n\nWhen Ridgeline Plots Make Sense\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe following code chunk is plotted using geom_density_ridges.\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nInsights: We see that class 3A has the highest English grades with higher data densities around 80.\nTo use geom_ridgeline() , we will need to explicitly calculate the density for each group (i.e., each CLASS in your example). This is because geom_density_ridges() automatically computes the density for you, whereas geom_ridgeline() requires the density data to be precomputed.\n\nStepsCode\n\n\n\nCompute the density for each group using ggplot2’s ggplot2::stat_density or base R/tidyverse tools.\nUse the computed density values as input to geom_ridgeline().\n\n\n\n\n# Compute density for each class\ndensity_data &lt;- exam %&gt;%\n  group_by(CLASS) %&gt;%\n  summarise(\n    density = list(density(ENGLISH, bw = 3.4)[c(\"x\", \"y\")]),\n    .groups = \"drop\"\n  ) %&gt;%\n  unnest_wider(density) %&gt;%\n  unnest(cols = c(x, y)) %&gt;%\n  mutate(y = y * 15)\n\nfill_color &lt;- alpha(\"#7097BB\", 0.7)\n\n# Create the plot\nggplot(density_data, aes(x = x, y = CLASS, height = y)) +\n  geom_ridgeline(\n    fill = fill_color,\n    color = \"white\",\n    min_height = 0.01\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL,\n    expand = expansion(add = c(0.2, 2.6))\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\nWe can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.This produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0, \n               point_colour = NA) #We remove the slab interval by setting .width = 0 and point_colour = NA\n\n\n\n\n\n\n\n\nInsights: More variations between the English scores are present for Chinese and Malay students which may also be because there are more students for these race.\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\nWe can even add values like median values on top of the boxplots to gain insights at a quick glance as shown in the figure below.\n\nsummary_stats &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(median = median(ENGLISH))\n\nggplot(exam, aes(x = RACE, y = ENGLISH)) +\n  stat_halfeye(\n    adjust = 0.5,\n    justification = -0.2,\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.20,\n    outlier.shape = NA\n  ) +\n  geom_text(\n    data = summary_stats, \n    aes(x = RACE, y = median, label = round(median, 1)), \n    vjust = -1.5, \n    size = 4, \n    color = \"blue\"\n  ) +\n  labs(\n    x = \"RACE\",\n    y = \"ENGLISH\",\n    title = \"Boxplot with Median Values\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "2.1 Installing and launching R packages",
    "text": "2.1 Installing and launching R packages\n\npacman::p_load(ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-1",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\nWe use the same code as above to import the data using tidyverse package.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#statistical-tests",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#statistical-tests",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "2.3 Statistical tests",
    "text": "2.3 Statistical tests\n\n2.3.1 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\n2.3.2 Unpacking the Bayes Factor\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10.\n\n\n2.3.3 Interpreting Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n2.3.4 Two-sample mean test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n2.3.5 One way ANOVA test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n2.3.6 Significant test of Correlation: ggscatterstats() method\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n2.3.7 Significant test of Association (Dependence): ggbarstats() method\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "2.4 Visualising Models",
    "text": "2.4 Visualising Models\nThe purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n2.4.1 Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n2.4.2 Importing Excel file: readxl methods\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n2.4.3 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\nInterpretation of Results:\nIntercept (-2.637e+06): the predicted price of a car when all predictor variables are 0. It indicates the baseline price offset before accounting for the effects of predictors.\nNegative coefficients (e.g., Age_08_04, KM) represent factors that reduce the resale price as their value increases.\nPositive coefficients (e.g., Mfg_Year, Weight, Guarantee_Period) represent factors that increase the resale price as their value increases.\n\n\n2.4.4 Model Diagnostic: checking for multicolinearity\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nVIF (Variance Inflation Factor): Measures how much the variance of a regression coefficient is inflated due to multicollinearity.\n\nA VIF &gt; 10 is typically considered problematic (indicating high multicollinearity).\nA VIF close to 1 indicates low or no multicollinearity.\n\nThe following predictors have severe multicollinearity:\n\nAge_08_04\nMfg_Year\n\nThese two predictors are highly correlated with one another. This is likely because Age_08_04 could represent the car’s age, which is inversely related to Mfg_Year (newer cars have smaller ages).\nIncluding both in the model leads to redundancy and instability in coefficient estimates. Retain only one out of this pair.\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n2.4.5 Model Diagnostic: checking for normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\nInterpretation of plot\n\nThe data points deviate from the line at both the lower and upper ends, indicating non-normality in the residuals.\nThis suggests potential skewness or heavy tails, meaning the model might not fully satisfy the normality assumption.\n\n\n\n2.4.6 Model Diagnostic: checking for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\nInterpretation of plot\n\nThe upward trend in the green smooth line and the increasing spread of points as fitted values grow indicate heteroscedasticity (non-constant variance).\nThis violates the homogeneity of variances assumption, suggesting that the model’s predictions might be less reliable for higher fitted values.\n\n\n\n2.4.7 Model Diagnostic: checking for complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n2.4.8 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n2.4.9 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\n\n\n\nInterpretation of plot\n\nAge_08_04 and KM have the largest negative impacts on the dependent variable, with highly significant p-values, indicating their strong influence.\nWeight and Guarantee_Period contribute positively, with Weight having a much stronger effect (and higher significance).\nThe low AIC and BIC values suggest the model may balance goodness of fit and complexity well."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-1",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "3.1 Installing and loading the packages",
    "text": "3.1 Installing and loading the packages\n\nPackagesCode\n\n\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-2",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "3.2 Importing data",
    "text": "3.2 Importing data\nWe use the same code as above to import the data using tidyverse package.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "3.3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "3.3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\nCode chunk below will be used to derive the necessary summary statistics.\n\nThings to NoteCode\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n3.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n3.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n3.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nLet’s plot interactive error bars for the 99% confidence interval of mean maths score by race.\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "3.4 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "3.4 Visualizing the uncertainty of point estimates: ggdist methods\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nWe can also use following arguments like :\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nMakeover of the plot on previous slide by showing 95% and 99% confidence intervals.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95,0.99),\n  .point = mean,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "3.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "3.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n3.5.1 Installing ungeviz package\nAs we already installed ungeviz in section 3.1, we will not do it again.\n\n\n3.5.2 Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "4.1 Installing and Launching R Packages",
    "text": "4.1 Installing and Launching R Packages\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-3",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-3",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "4.2 Importing Data",
    "text": "4.2 Importing Data\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "4.3 FunnelPlotR methods",
    "text": "4.3 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n4.3.1 The Basic Plot\n\nCodeThings to Note\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\n\n\n4.3.2 Makeover 1\n\nCodeThings to Note\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\ndata_type argument is used to change from default “SR” to “PR” (i.e. proportions).\nxrange and yrange are used to set the range of x-axis and y-axis\n\n\n\n\n\n\n4.3.3 Makeover 2\n\nCodeThings to Note\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 04: Fundamentals of Visual Analytics",
    "section": "4.4 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "4.4 Funnel Plot for Fair Visual Comparison: ggplot2 methods\n\n4.4.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n4.4.2 Calculate lower and upper limits for 95% and 99.9% CI\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n4.4.3 Plotting a static funnel plot\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n4.4.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "tidyverse loose coupling approach (each of the packages upgrade independently), don’t have to upgrade and rewrap like panda\n\ndplyr: data transformation\nggplot2: build statistical plots\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse,ggstatsplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-data-types",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-data-types",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.5 Convert Data Types",
    "text": "4.5 Convert Data Types\nWe note that all variables are in the correct data types. However, we will convert the categorical columns such as Smoking_History, Diabetes_History, Hypertension_History, Family_History Heart_Attack_Occurrence, and our newly created columns as factor for better visualisation and to put the categories in order.\n\nheartattack_data &lt;- heartattack_data %&gt;%\n  mutate(\n    Smoking_History = factor(Smoking_History, levels = c(\"No\", \"Yes\")),\n    Diabetes_History = factor(Diabetes_History, levels = c(\"No\", \"Yes\")),\n    Hypertension_History = factor(Hypertension_History, levels = c(\"No\", \"Yes\")),\n    Family_History = factor(Family_History, levels = c(\"No\", \"Yes\")),\n    Heart_Attack_Occurrence = factor(Heart_Attack_Occurrence, levels = c(\"No\", \"Yes\")),\n    \n    # Setting specific orders for more than 2 categorical factors\n    Alcohol_Consumption = factor(Alcohol_Consumption, levels = c(\"None\", \"Low\", \"Moderate\", \"High\")),\n    Diet_Quality = factor(Diet_Quality, levels = c(\"Poor\", \"Average\", \"Good\")),\n    Physical_Activity = factor(Physical_Activity, levels = c(\"Low\", \"Moderate\", \"High\")),\n    AgeCat = factor(AgeCat, levels = c(\"Young\", \"Middle-Aged\", \"Old\")),\n    Stress = factor(Stress, levels = c(\"Low\", \"Medium\", \"High\"))\n  )\n\nLastly, save the prepared output to rds format using the following code chunk. We will use this newly prepared data from this point.\n\nSave to .rds formatLoad the rds file\n\n\n\nwrite_rds(heartattack_data, file = \"data/rds/heartattack.rds\")\n\n\n\n\nheartattack &lt;- read_rds(\"data/rds/heartattack.rds\")\n\n\n\n\nWe will also create a separate subset of the dataset for individuals who reported ‘Yes’ for Heart Attack Occurrence, enabling us to conduct further analysis and visualisations on the distribution with a focus on this specific group.\n\nSubsetSave to .rds formatLoad the rds file\n\n\n\nyesheartattack &lt;- heartattack %&gt;%\n  filter(Heart_Attack_Occurrence == \"Yes\")\n\n\n\n\nwrite_rds(yesheartattack, file = \"data/rds/yesheartattack.rds\")\n\n\n\n\nyesheartattack &lt;- read_rds(\"data/rds/yesheartattack.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-data-types-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-data-types-1",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.5 Convert Data Types",
    "text": "4.5 Convert Data Types\nLastly, save the prepared output to rds format using the following code chunk. We will use this newly prepared data from this point.\n\nSave to .rds formatLoad the rds file\n\n\n\nwrite_rds(heartattack_data, file = \"data/rds/heartattack.rds\")\n\n\n\n\nheartattack &lt;- read_rds(\"data/rds/heartattack.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#starting-big-overview-of-heart-attack-occurrence-in-japan",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#starting-big-overview-of-heart-attack-occurrence-in-japan",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Starting Big: Overview of Heart Attack Occurrence in Japan",
    "text": "5.2 Starting Big: Overview of Heart Attack Occurrence in Japan\n\n5.2.1 Association of Heart Attack Occurrence with Continuous Factors\nTo determine whether numerical factors are associated with heart attack occurrence, we will first assess the distribution of each continuous variable. The following will be tested:\n\nNull Hypothesis: There is no significant difference in continuous factors between individuals with and without a heart attack.\nAlternative Hypothesis: There is a significant difference in continuous factors between individuals with and without a heart attack.\n\nTo decide whether to use the Welch’s t-test (for normally distributed data) or the Mann-Whitney U test (for non-normally distributed data), we will first check the normality of each continuous variable by plotting histograms as shown below. geom_histogram() from ggplot2 package to plot the histograms.\n\n\n\n\n\n\n\n\n\nSince all six continuous variables follow a normal distribution, we will use the Welch’s t-test for comparing means between groups. The ggbetweenstats() function from the ggstatsplot package allows us to visualize the distribution of a continuous variable across categorical groups while simultaneously performing statistical test to test our hypothesis. In this case, we will specify Welch’s t-test using type = \"p\" within ggbetweenstats().\n\nBMI + StressCholesterol + Heart RateSystolic + Diastolic BP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.2 Association of Heart Attack Occurrence with Categorical Factors\nNext, we will conduct hypothesis testing for the categorical variables as well. We will use ggbarstats() from the ggstatsplot package to assess statistical significance while visualizing the proportions and distribution of categorical factors in a stacked bar chart. This function performs appropriate statistical tests to determine associations between categorical variables.\n\nDiabetes + Alcohol ConsumptionSmoking + Family HistoryDiet Quality + Physical Activity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nThe Welch’s t-test for Stress Level has a p-value of 0.04, indicating a statistically significant difference in stress levels between individuals with and without a heart attack.\nThe mean stress level is slightly lower for individuals who had a heart attack (4.93) compared to those who did not (5.01), but the effect size (g hedges​=0.04) suggests a very small difference. While statistically significant, this difference may not be clinically meaningful.\nBMI, Cholesterol Level, Heart Rate, Systolic BP, Diastolic BP and all categorical variables had p-values greater than 0.05, indicating no significant differences between individuals with and without a heart attack. This suggests that these factors, in isolation, do not show strong evidence of a direct association with heart attack occurrence in this dataset.\nApart from Stress, we fail to reject the null hypothesis that there is no significant difference between individuals with and without a heart attack for the rest of the variables.\n\n\n\n\n\n5.2.3 Overview of Heart Attack Cases: The Demographics\nNow that we have an understanding of the distributions and significance of the variables against heart attack occurrence, we will first explore the distribution of heart attack occurrences across different age groups and genders in Japan. By categorizing individuals into age groups (Young, Middle-Aged, and Old), we can observe trends in heart attack prevalence, with particular focus on gender differences. This helps identify which demographic groups are more vulnerable and gives us the overview.\n\n\n\n\n\n\nAdjustment for Age Category Imbalance\n\n\n\nIn section 5.1, it was observed that the Young Age Group (36%) is naturally more represented in the dataset. If we analyze the data without adjustment, this could lead to an overemphasis on the risk of heart attacks among young individuals. To mitigate this potential bias, we will normalize the prevalence of heart attacks within each age group by accounting for their overall representation in the dataset.\nThe prevalence of heart attack in each age category will be calculated using the following formula:\n\\(PrevalenceAgeCat\\) = Number of Heart Attack Cases in Age Group/ Total Individuals in Age Group\nThis adjustment ensures that the analysis of heart attack risk is proportionate to the actual representation of each age group in the dataset, providing more accurate insights into the relationship between age and heart attack prevalence.\n\n\nFor this visualization, we will use geom_bar() from the ggplot2 package to create bar charts and leverage the patchwork package to seamlessly combine multiple bar charts into a cohesive layout.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute total individuals in each age category (from full dataset)\ntotal_age_counts &lt;- heartattack %&gt;%\n  group_by(AgeCat) %&gt;%\n  summarise(TotalCount = n())\n\n# Compute number of heart attack cases in each age category (from filtered dataset)\nage_summary &lt;- yesheartattack %&gt;%\n  group_by(AgeCat) %&gt;%\n  summarise(HeartAttackCases = n()) %&gt;%\n  left_join(total_age_counts, by = \"AgeCat\") %&gt;%\n  mutate(PrevalenceAgeCat = (HeartAttackCases / TotalCount) * 100)\n\ncustom_colors &lt;- c(\"Young\" = \"#ffe372\", \"Middle-Aged\" = \"#9cc567\", \"Old\" = \"#e79251\")\n\n# Plot 1: Heart Attack Occurrence by Age Category \np1 &lt;- ggplot(age_summary, aes(x = AgeCat, y = PrevalenceAgeCat, fill = AgeCat)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.2f%%\", PrevalenceAgeCat)), vjust = 1.5, size = 3) +  \n  scale_fill_manual(values = custom_colors) +\n  labs(x = \"Age Category\") +  \n  theme_minimal() +\n  theme(legend.position = \"none\", plot.title = element_blank(), \n        axis.title.y = element_blank(),axis.text.y = element_blank(), axis.title.x = element_blank())  \n\n# Compute percentage of Heart Attack Occurrence for each Gender\ngender_summary &lt;- yesheartattack %&gt;%\n  group_by(Gender) %&gt;%\n  summarise(Percentage = (n() / nrow(yesheartattack)) * 100)\n\n# Plot 2: Heart Attack Occurrence by Gender \np2 &lt;- ggplot(gender_summary, aes(x = Gender, y = Percentage, fill = Gender)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), vjust = 1.5, size = 3) + \n  labs(x = \"Gender\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", plot.title = element_blank(), axis.title.y = element_blank(),axis.text.y = element_blank(),axis.title.x = element_blank())+\n  scale_fill_manual(values = c(\"Female\" = \"#f7a8b8\", \"Male\" = \"#83bace\"))\n\n# Compute total individuals for each Gender-Age category\ntotal_gender_age_counts &lt;- heartattack %&gt;%\n  group_by(Gender, AgeCat) %&gt;%\n  summarise(TotalCount = n())\n\n# Compute heart attack cases for each Gender-Age category\ngender_age_summary &lt;- yesheartattack %&gt;%\n  group_by(Gender, AgeCat) %&gt;%\n  summarise(HeartAttackCases = n()) %&gt;%\n  left_join(total_gender_age_counts, by = c(\"Gender\", \"AgeCat\")) %&gt;%\n  mutate(PrevalenceAgeCat = (HeartAttackCases / TotalCount) * 100)\n\n# Gender-Age Barplot\np3 &lt;- ggplot(gender_age_summary, aes(x = Gender, y = PrevalenceAgeCat, fill = AgeCat)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +  \n  geom_text(aes(label = sprintf(\"%.1f%%\", PrevalenceAgeCat)), \n            position = position_dodge(width = 0.9), vjust = 1.5, size = 3) + \n  scale_fill_manual(values = custom_colors) +\n  labs(x = \"Gender\", y = \"Prevalence of Heart Attack Cases (%)\", fill = \"Age Category\") +\n  theme_minimal()+\n  theme(axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.text.y = element_blank())\n\n\n\n(p1 + p2)/ p3 + \n  plot_layout(widths = c(1, 1, 1.5)) +  \n  plot_annotation(title = \"Proportion of Heart Attack Cases in Age Groups and Gender\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nMales have a slightly higher proportion of heart attack cases than females, suggesting gender may be a factor.\nAmong those who experienced heart attacks, a higher percentage are in the Middle Aged Group (10.0%).\n\nAmong females, the Old Age Group is the most vulnerable.\nAmong males, the Middle-Aged Age Group appears to be the most vulnerable to heart attacks."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#narrowing-down-risk-factors-and-their-impact",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#narrowing-down-risk-factors-and-their-impact",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Narrowing Down: Risk Factors and Their Impact",
    "text": "5.2 Narrowing Down: Risk Factors and Their Impact\nAs we delve deeper into understanding heart attack occurrence, it’s essential to focus on the specific risk factors that influence this outcome. This section aims to narrow our focus from a broad overview of heart attacks to the key lifestyle and health factors that directly contribute to their occurrence. By investigating these factors in more detail, we aim to uncover how individual behaviors, medical histories, and other characteristics interact to influence heart attack risk.\n\n5.2.1 Smoking’s Impact on Heart Attack Occurrence by Age\nSmoking has long been established as one of the most significant risk factors for heart disease, and understanding its impact across different age groups is crucial for targeted interventions. Age plays a vital role in how smoking affects heart health, with younger and older individuals potentially experiencing different risks due to variations in metabolism, vascular health, and overall lifestyle. By examining smoking’s influence on heart attack occurrence across various age groups, we can gain a better understanding of which populations are most vulnerable.\nWe will do this by calculating the rate of heart attacks occurring in each group. For instance, Number of Heart Attacks in YoungSmokers/ Total Number of YoungSmokers.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\n\n\n\n\n\n\n5.2.2 Diabetes & Hypertension Impact by Age (X)\n\n\n5.2.3 BMI vs. Heart Attack with Physical Activity Levels\n\nBMI Distribution (Boxplot + Violin Plot)\n\n\n\n\n5.2.4 Stress vs. Heart Attack by Gender and Region\n\nBy GenderBy Region\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nAt lower stress levels (0-1, 1-2), the proportions are relatively high for both genders (11-12%), with males having slightly higher values.\nAt the highest stress level (9-10), females have a noticeably higher proportion (12.01%) compared to males (10.45%). This suggests that extreme stress levels might have a higher association with heart attacks in females compared to males.\nAt lower stress levels (0-1, 1-2), rural areas show a higher proportion of heart attack occurrences than urban areas.\nAt the highest stress level (9-10), urban areas show a higher proportion of heart attack occurrences (11.55%) compared to rural areas (10.42%), suggesting that lower stress levels are associated with more heart attack occurrences in rural areas, while higher stress levels have a greater impact in urban areas.\n\n\n\n\n\n5.2.5 Heart Rate & BP Comparison\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Diastolic_BP,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n5.2.6 Cholesterol Level\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Heart_Rate,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Cholesterol_Level,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\ncho &lt;- heartattack %&gt;% \n  mutate(Cho_bins = cut(Cholesterol_Level, \n                        breaks = c(80, 150, 200, 240, 300),  \n                        labels = c(\"Low\", \"Desirable\", \"Borderline High\", \"High\"),\n                        include.lowest = TRUE))\n\nggbarstats(cho, \n           x = Cho_bins, \n           y = Heart_Attack_Occurrence)\n\n\n\n\n\n\n\n\n\nggplot(heartattack, aes(x = Gender_HeartAttack_Interaction, y = Cholesterol_Level, fill = Gender)) +\n  geom_violin(trim = FALSE, alpha = 0.5) +  \n  geom_boxplot(width = 0.2, color = \"black\", alpha = 0.7) +  \n  labs(x = \"Gender & Heart Attack Occurrence\", y = \"Stress Level\",\n       title = \"Distribution of Stress Levels by Gender and Heart Attack Occurrence\") +\n  scale_fill_manual(values = c(\"Female\" = \"#e67ea2\", \"Male\" = \"#1f78b4\")) +  \n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#clinical-insights",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#clinical-insights",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.3 Clinical Insights",
    "text": "5.3 Clinical Insights\n\n5.3.1 Correlation between BMI and Heart Attack\n\n\n5.3.2 Blood Pressure vs. Heart Rate Among Heart Attack Patients (Regression)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-interaction-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-interaction-variables",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.5 Deriving Interaction Variables",
    "text": "4.5 Deriving Interaction Variables\n\n4.5.1 Gender & Age\n\nheartattack_data$Gender_AgeCat_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Gender == \"Female\" & AgeCat == \"Young\", \"YoungFemale\", \n                                                                ifelse(Gender == \"Female\" & AgeCat == \"Middle-Aged\", \"Middle-AgedFemale\", ifelse(Gender == \"Female\" & AgeCat == \"Old\", \"OldFemale\", \n                                                                       ifelse(Gender == \"Male\" & AgeCat == \"Young\", \"YoungMale\",ifelse(Gender == \"Male\" & AgeCat == \"Middle-Aged\", \"Middle-AgedMale\", \"OldMale\"))))))\n\n\n\n4.5.2 Gender & HeartAttack\n\nheartattack_data$Gender_HeartAttack_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Gender == \"Female\" & Heart_Attack_Occurrence == \"Yes\", \"Female with HeartAttack\", \n                                                                ifelse(Gender == \"Female\" & Heart_Attack_Occurrence == \"No\", \"Female without HeartAttack\", \n                                                                       ifelse(Gender == \"Male\" & Heart_Attack_Occurrence == \"Yes\", \"Male with HeartAttack\", \"Male without HeartAttack\"))))\n\n\n\n4.5.3 Region & HeartAttack\n\nheartattack_data$Region_HeartAttack_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Region == \"Urban\" & Heart_Attack_Occurrence == \"Yes\", \"Urban HeartAttack\", \n                                                                ifelse(Region == \"Urban\" & Heart_Attack_Occurrence == \"No\", \"Urban No HeartAttack\", \n                                                                       ifelse(Region == \"Rural\" & Heart_Attack_Occurrence == \"Yes\", \"Rural HeartAttack\", \"Rural No HeartAttack\"))))\n\n\n\n4.5.4 BMI & Stress\n\nheartattack_data$Stress_BMI_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(BMICat == \"Overweight\" & Stress == \"High\", \"HighStressOverweight\", \n                                                                ifelse(BMICat == \"Overweight\" & Stress == \"Medium\", \"MedStressOverweight\",  ifelse(BMICat == \"Overweight\" & Stress == \"Low\", \"LowStressOverweight\", \n                                                                                                                                                   ifelse(BMICat == \"Normal\" & Stress == \"High\", \"HighStressNormal\", \n                                                                ifelse(BMICat == \"Normal\" & Stress == \"Medium\", \"MedStressNormal\",  ifelse(BMICat == \"Normal\" & Stress == \"Low\", \"LowStressNormal\", \n                                                                                                                                                   ifelse(BMICat == \"Underweight\" & Stress == \"High\", \"HighStressUnderweight\", \n                                                                ifelse(BMICat == \"Underweight\" & Stress == \"Medium\", \"MedStressUnderweight\",  \"LowStressUnderweight\" )))))))))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#narrowing-down-bmi",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#narrowing-down-bmi",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Narrowing Down: BMI",
    "text": "5.2 Narrowing Down: BMI\nAs we delve deeper into understanding heart attack occurrence, it’s essential to focus on the specific risk factors that influence this outcome. This section aims to narrow our focus from a broad overview of heart attacks to the key health factors, BMI, that directly contribute to their occurrence. By investigating these factors in more detail, we aim to uncover how individual behaviors, medical histories, and other characteristics interact to influence heart attack risk.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggbarstats(\n  data = heartattack,\n  x = BMICat,\n  y = Heart_Attack_Occurrence,\n  results.subtitle = FALSE\n) +\n  labs(title = NULL) +  # Remove subtitle\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        plot.title = element_text(hjust = 0.5)) + \n  ggtitle(\"Heart Attack Occurrence by BMI\") +\n  scale_fill_manual(values = c(\"Underweight\" = \"#d6f0f9\", \n                               \"Normal\" = \"#83bace\", \n                               \"Overweight\" = \"#0d8ab7\")) \n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nOverweight and Normal categories have a very similar distribution for both groups (those who had heart attacks and those who didn’t), suggesting that overweight individuals are still more prevalent in both groups.\nVulnerability to heart attack based on BMI:\n\nThe proportions of overweight and normal weight individuals are almost identical for both those who had a heart attack and those who did not.\nHowever, the significance (p-value = 0.04) tells us that there might be a real association between BMI category and the likelihood of having a heart attack, but overweight individuals do not show a notably higher proportion of heart attack occurrence in this dataset compared to other categories.\n\n\n\n\n\n5.2.1 BMI vs. Heart Attack by Gender\n\nBMI Distribution (Boxplot + Violin Plot)\n\n\n\n\n5.2.2 BMI vs. Heart Attack by Physical Activity\n\n\n5.2.3 Cholesterol Level\n\ncho &lt;- heartattack %&gt;% \n  mutate(Cho_bins = cut(Cholesterol_Level, \n                        breaks = c(80, 150, 200, 240, 300),  \n                        labels = c(\"Low\", \"Desirable\", \"Borderline High\", \"High\"),\n                        include.lowest = TRUE))\n\nggbarstats(cho, \n           x = Cho_bins, \n           y = Heart_Attack_Occurrence)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html",
    "href": "Take-home_Ex/Take-home_Ex01/first.html",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "Heart disease remains one of the leading causes of mortality worldwide, and Japan is no exception. Despite the country’s reputation for longevity and a traditionally healthy diet, heart-related health issues—including heart attacks—continue to be a significant public health concern. The impact of heart attacks varies across different age groups, with risk factors and outcomes often differing between younger and older individuals. While Japan’s aging population naturally sees a higher prevalence of heart attacks among adults, recent trends suggest that younger individuals are also increasingly at risk, raising concerns about lifestyle habits and diet.\nHistorically, Japan’s diet—rich in fish, vegetables, and low in saturated fats—has been associated with lower cardiovascular disease rates. However, research by Iso (2011) has highlighted a gradual shift toward Westernized dietary patterns, characterized by increased consumption of meat and processed foods, which has contributed to rising cholesterol levels and a greater risk of heart disease. Additionally, lifestyle factors such as physical inactivity, smoking, and alcohol consumption have played a role in shaping cardiovascular health trends within the country.\nMedical advancements and early interventions have improved survival rates, but the rising burden of cardiovascular diseases still calls for further research and public awareness.\n\n\n\nThis exercise aims to explore the patterns of heart attacks in Japan across different age groups and shedding light on key factors contributing to their occurrence. By examining trends, potential risk factors, and demographic variations, I seek to provide insights into how heart attack cases differ between youth and adults.\nThrough data-driven visualizations, I will highlight the prevalence, underlying causes, and potential warning signs associated with heart attacks in Japan. The goal is to help healthcare professionals, policymakers, and the general public better understand the evolving landscape of cardiovascular health and to encourage proactive measures for prevention and early detection."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#background",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "Heart disease remains one of the leading causes of mortality worldwide, and Japan is no exception. Despite the country’s reputation for longevity and a traditionally healthy diet, heart-related health issues—including heart attacks—continue to be a significant public health concern. The impact of heart attacks varies across different age groups, with risk factors and outcomes often differing between younger and older individuals. While Japan’s aging population naturally sees a higher prevalence of heart attacks among adults, recent trends suggest that younger individuals are also increasingly at risk, raising concerns about lifestyle habits and diet.\nHistorically, Japan’s diet—rich in fish, vegetables, and low in saturated fats—has been associated with lower cardiovascular disease rates. However, research by Iso (2011) has highlighted a gradual shift toward Westernized dietary patterns, characterized by increased consumption of meat and processed foods, which has contributed to rising cholesterol levels and a greater risk of heart disease. Additionally, lifestyle factors such as physical inactivity, smoking, and alcohol consumption have played a role in shaping cardiovascular health trends within the country.\nMedical advancements and early interventions have improved survival rates, but the rising burden of cardiovascular diseases still calls for further research and public awareness."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#objectives",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "",
    "text": "This exercise aims to explore the patterns of heart attacks in Japan across different age groups and shedding light on key factors contributing to their occurrence. By examining trends, potential risk factors, and demographic variations, I seek to provide insights into how heart attack cases differ between youth and adults.\nThrough data-driven visualizations, I will highlight the prevalence, underlying causes, and potential warning signs associated with heart attacks in Japan. The goal is to help healthcare professionals, policymakers, and the general public better understand the evolving landscape of cardiovascular health and to encourage proactive measures for prevention and early detection."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#importing-the-data",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.1 Importing the Data",
    "text": "4.1 Importing the Data\nThe code chunk below imports japan_heart_attack_dataset.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nheartattack_data &lt;- read_csv(\"data/raw/japan_heart_attack_dataset.csv\")\n\nLet’s view the structure of the dataset using glimpse(), which allows us to see data structure and variable names as well as types.\n\nglimpse(heartattack_data)\n\nRows: 30,000\nColumns: 32\n$ Age                     &lt;dbl&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Region                  &lt;chr&gt; \"Urban\", \"Urban\", \"Rural\", \"Urban\", \"Rural\", \"…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Hypertension_History    &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Diet_Quality            &lt;chr&gt; \"Poor\", \"Good\", \"Average\", \"Good\", \"Good\", \"Go…\n$ Alcohol_Consumption     &lt;chr&gt; \"Low\", \"Low\", \"Moderate\", \"High\", \"High\", \"Hig…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Heart_Rate              &lt;dbl&gt; 72.30153, 57.45764, 64.65870, 55.13147, 76.667…\n$ Systolic_BP             &lt;dbl&gt; 123.90209, 129.89331, 145.65490, 131.78522, 10…\n$ Diastolic_BP            &lt;dbl&gt; 85.68281, 73.52426, 71.99481, 68.21133, 92.902…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ Extra_Column_1          &lt;dbl&gt; 0.40498852, 0.03627815, 0.85297888, 0.39085280…\n$ Extra_Column_2          &lt;dbl&gt; 0.43330004, 0.51256694, 0.21959083, 0.29684675…\n$ Extra_Column_3          &lt;dbl&gt; 0.62871236, 0.66839275, 0.61343656, 0.15572404…\n$ Extra_Column_4          &lt;dbl&gt; 0.70160955, 0.11552874, 0.50800995, 0.87025144…\n$ Extra_Column_5          &lt;dbl&gt; 0.49814235, 0.42381938, 0.90066981, 0.39035591…\n$ Extra_Column_6          &lt;dbl&gt; 0.007901312, 0.083932768, 0.227205241, 0.40318…\n$ Extra_Column_7          &lt;dbl&gt; 0.79458257, 0.68895108, 0.49634358, 0.74140891…\n$ Extra_Column_8          &lt;dbl&gt; 0.29077922, 0.83016364, 0.75210679, 0.22396813…\n$ Extra_Column_9          &lt;dbl&gt; 0.49719307, 0.63449028, 0.18150125, 0.32931387…\n$ Extra_Column_10         &lt;dbl&gt; 0.52199452, 0.30204337, 0.62918031, 0.14319054…\n$ Extra_Column_11         &lt;dbl&gt; 0.79965663, 0.04368285, 0.01827617, 0.90778075…\n$ Extra_Column_12         &lt;dbl&gt; 0.72239788, 0.45166789, 0.06322702, 0.54232201…\n$ Extra_Column_13         &lt;dbl&gt; 0.1487387, 0.8786714, 0.1465122, 0.9224606, 0.…\n$ Extra_Column_14         &lt;dbl&gt; 0.8340099, 0.5356022, 0.9972962, 0.6262165, 0.…\n$ Extra_Column_15         &lt;dbl&gt; 0.061632229, 0.617825340, 0.974455410, 0.22860…\n\n\nAt a glimpse, we see that there at 32,000 rows and 32 columns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#filtering-for-relevant-variables",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#filtering-for-relevant-variables",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.2 Filtering for Relevant Variables",
    "text": "4.2 Filtering for Relevant Variables\nWe notice that there were certain columns titled “Extra_Column_” from column number 18 to 32. We will remove these columns as there are no explanations in the metadata from the source, leaving us with 17 variables to work with.\n\nheartattack_data &lt;- heartattack_data %&gt;% select(-c(18:32))\n\nWe also notice that this dataset also contains data for people with no heart attack occurrence (in the Heart_Attack_Occurrence column). Since we are performing exploratory data analysis (EDA), it would be valuable to keep both groups, as this allows us to identify and compare characteristics like age, gender, lifestyle, or pre-existing conditions between those who had a heart attack and those who didn’t, potentially letting us uncover patterns or trends that can inform your study."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#checking-for-duplicates-and-missing-values",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#checking-for-duplicates-and-missing-values",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.3 Checking for Duplicates and Missing values",
    "text": "4.3 Checking for Duplicates and Missing values\nIt is essential to check for duplicates and missing values before we move forward. We will use the following code to check for them.\n\nChecking for DuplicatesChecking for Missing Values\n\n\nThe duplicated() function in the base package is used to check for duplicates in heartattack_data.\n\nsum(duplicated(heartattack_data))\n\n[1] 0\n\n\n\n\nThe colSums() function in the base package is used to check for missing values in heartattack_data.\n\ncolSums(is.na(heartattack_data))\n\n                    Age                  Gender                  Region \n                      0                       0                       0 \n        Smoking_History        Diabetes_History    Hypertension_History \n                      0                       0                       0 \n      Cholesterol_Level       Physical_Activity            Diet_Quality \n                      0                       0                       0 \n    Alcohol_Consumption           Stress_Levels                     BMI \n                      0                       0                       0 \n             Heart_Rate             Systolic_BP            Diastolic_BP \n                      0                       0                       0 \n         Family_History Heart_Attack_Occurrence \n                      0                       0 \n\n\n\n\n\nThere are no duplicates and missing values in this dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#grouping-variables-into-categories",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#grouping-variables-into-categories",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.4 Grouping Variables into Categories",
    "text": "4.4 Grouping Variables into Categories\nSome numerical variables (represented as “dbl” when we checked data structure in section 4.1), will be grouped into the following categories for meaningful insights:\n\nAge: For this variable which ranges from 18 to 79, we will use equal bins for each category, categorized as:\n\nYoung: 18–39\nMiddle-Aged: 40–59\nOld: 60–79\n\nCholesterol Level: According to guidelines from the American Heart Association (AHA) and National Heart, Lung, and Blood Institute (NHLBI) (Lauer et al, 2004), a desirable low cholesterol level is Below 200 mg/dL, a borderline high medium would be between 200 to 239 mg/dL and high cholesterol level is considered as 240 mg/dL and above.To align with this finding, we will categorize as:\n\nLow: 80–199 mg/dL\nMedium: 200–239 mg/dL\nHigh: 240–336 mg/dL\n\nStress Level: A common method to measure stress is the Perceived Stress Scale (Cohen,1994) where individuals rate their stress from 0 (no stress) to 10 (extreme stress). Since our dataset usesa 0 to 10 range, it’s likely a self-reported scale, where 0-3 represents minimal or manageable stress, 4-6 represents moderate stress and 7-10 represents high to extreme stress, with potential health risks. Therefore, we will categorize the stress levels as:\n\nLow: 0.000–3.999\nMedium: 4.000–6.999\nHigh: 7.000–10.000\n\nHeart Rate: According to Mayo Clinic, low/below normal heart rate is below 60 bpm, a normal healthy range is 60–100 bpm, and above normal is above 100 bpm. Aligning with this, our categories will be:\n\nLow: 30.000–59.999 bpm\nNormal: 60.000–99.999 bpm\nHigh: 100.000–108.7812 bpm\n\n\n\nheartattack_data &lt;- heartattack_data %&gt;%\n  mutate(\n    AgeCat = case_when(\n      Age &gt;= 18 & Age &lt;= 39 ~ \"Young\",\n      Age &gt;= 40 & Age &lt;= 59 ~ \"Middle-Aged\",\n      Age &gt;= 60 & Age &lt;= 79 ~ \"Old\"\n    ),\n    \n    Cholesterol = case_when(\n      Cholesterol_Level &gt;= 80.0000 & Cholesterol_Level  &lt;= 199.9999 ~ \"Low\",\n      Cholesterol_Level  &gt;= 200.0000 & Cholesterol_Level  &lt;= 239.9999 ~ \"Medium\",\n      Cholesterol_Level  &gt;= 240.0000 & Cholesterol_Level  &lt;= 336.9999 ~ \"High\"\n    ),\n    \n    Stress = case_when(\n      Stress_Levels &gt;= 0.000 & Stress_Levels &lt;= 3.999999 ~ \"Low\",\n      Stress_Levels &gt; 4.000 & Stress_Levels &lt;= 6.999999 ~ \"Medium\",\n      Stress_Levels &gt; 7.000 & Stress_Levels &lt;= 10.000 ~ \"High\"\n    ),\n    \n    HeartRate = case_when(\n      Heart_Rate &gt;= 30.000 & Heart_Rate &lt;= 59.99999 ~ \"Low\",\n      Heart_Rate &gt; 60.000 & Heart_Rate &lt;= 99.99999 ~ \"Normal\",\n      Heart_Rate &gt; 100.000 & Heart_Rate &lt;= 108.78217 ~ \"High\"\n    ),\n    BMICat = case_when(\n      BMI &gt;= 0 & BMI &lt;= 17.999999 ~ \"Underweight\",\n      BMI &gt; 18 & BMI &lt;= 24.999999 ~ \"Normal\",\n      BMI &gt; 25 ~ \"Overweight\"\n    )\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#deriving-interaction-variables",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#deriving-interaction-variables",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.6 Deriving Interaction Variables",
    "text": "4.6 Deriving Interaction Variables\n\n4.6.1 Smoking & Heart Attack Occurrence\n\nheartattack_data$Smoking_HeartAttack_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Smoking_History == \"Yes\" & Heart_Attack_Occurrence == \"Yes\", \"Smoker with Heart Attack\", \n                                                                ifelse(Smoking_History == \"Yes\" & Heart_Attack_Occurrence == \"No\", \"Smoker without Heart Attack\", \n                                                                       ifelse(Smoking_History == \"No\" & Heart_Attack_Occurrence == \"Yes\", \"NonSmoker with Heart Attack\", \"NonSmoker without Heart Attack\"))))\n\n\nheartattack_data$FamilyHistory_HeatAttack_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Family_History == \"Yes\" & Heart_Attack_Occurrence == \"Yes\", \"Have Family History and Heart Attack\", \n                                                                ifelse(Family_History == \"Yes\" & Heart_Attack_Occurrence == \"No\", \"Have Family History without Heart Attack\", \n                                                                       ifelse(Family_History == \"No\" & Heart_Attack_Occurrence == \"Yes\", \"No Family History but have Heart Attack\", \"No Family History and No Heart Attack\"))))\n\n\nheartattack_data$Gender_AgeCat_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Gender == \"Female\" & AgeCat == \"Young\", \"YoungFemale\", \n                                                                ifelse(Gender == \"Female\" & AgeCat == \"Middle-Aged\", \"Middle-AgedFemale\", ifelse(Gender == \"Female\" & AgeCat == \"Old\", \"OldFemale\", \n                                                                       ifelse(Gender == \"Male\" & AgeCat == \"Young\", \"YoungMale\",ifelse(Gender == \"Male\" & AgeCat == \"Middle-Aged\", \"Middle-AgedMale\", \"OldMale\"))))))\n\n\nheartattack_data$Gender_HeartAttack_Interaction &lt;- with(heartattack_data, \n                                                         ifelse(Gender == \"Female\" & Heart_Attack_Occurrence == \"Yes\", \"Female with HeartAttack\", \n                                                                ifelse(Gender == \"Female\" & Heart_Attack_Occurrence == \"No\", \"Female without HeartAttack\", \n                                                                       ifelse(Gender == \"Male\" & Heart_Attack_Occurrence == \"Yes\", \"Male with HeartAttack\", \"Male without HeartAttack\"))))\n\n\nheartattack_data$Smoking_Age_Interaction &lt;- with(heartattack_data, \n                                          ifelse(Smoking_History == \"Yes\" & AgeCat == \"Young\", \"YoungSmoker\", \n                                          ifelse(Smoking_History == \"Yes\" & AgeCat == \"Middle-Aged\", \"Middle-AgedSmoker\", \n                                          ifelse(Smoking_History == \"Yes\" & AgeCat == \"Old\", \"OldSmoker\",  ifelse(Smoking_History == \"No\" & AgeCat == \"Young\", \"YoungNonSmoker\", \n                                                                ifelse(Smoking_History == \"No\" & AgeCat == \"Middle-Aged\", \"Middle-AgedNonSmoker\",\"OldNonSmoker\"))))))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#convert-data-types",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#convert-data-types",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "4.6 Convert Data Types",
    "text": "4.6 Convert Data Types\nWe note that all variables are in the correct data types. However, we will convert the categorical columns such as Smoking_History,Diabetes_History, Hypertension_History, Family_History Heart_Attack_Occurrence, and our newly created columns as factor for better visualisation and to put the categories in order.\n\nheartattack_data &lt;- heartattack_data %&gt;%\n  mutate(\n    Smoking_History = factor(Smoking_History, levels = c(\"No\", \"Yes\")),\n    Diabetes_History = factor(Diabetes_History, levels = c(\"No\", \"Yes\")),\n    Hypertension_History = factor(Hypertension_History, levels = c(\"No\", \"Yes\")),\n    Family_History = factor(Family_History, levels = c(\"No\", \"Yes\")),\n    Heart_Attack_Occurrence = factor(Heart_Attack_Occurrence, levels = c(\"No\", \"Yes\")),\n    \n    # Setting specific orders for more than 2 categorical factors\n    Alcohol_Consumption = factor(Alcohol_Consumption, levels = c(\"None\", \"Low\", \"Moderate\", \"High\")),\n    Diet_Quality = factor(Diet_Quality, levels = c(\"Poor\", \"Average\", \"Good\")),\n    Physical_Activity = factor(Physical_Activity, levels = c(\"Low\", \"Moderate\", \"High\")),\n    AgeCat = factor(AgeCat, levels = c(\"Young\", \"Middle-Aged\", \"Old\")),\n    Cholesterol = factor(Cholesterol, levels = c(\"Low\", \"Medium\", \"High\")),\n    Stress = factor(Stress, levels = c(\"Low\", \"Medium\", \"High\")),\n    HeartRate = factor(HeartRate, levels = c(\"Low\", \"Normal\", \"High\")),\n    BMICat = factor(BMICat, levels = c(\"Underweight\", \"Normal\", \"Overweight\")),\n    Gender_AgeCat_Interaction =factor(Gender_AgeCat_Interaction, levels = c(\"YoungFemale\", \"YoungMale\", \"Middle-AgedFemale\",\"Middle-AgedMale\",\"OldFemale\",\"OldMale\"))\n  )\n\nLastly, save the prepared output to rds format using the following code chunk. We will use this newly prepared data from this point.\n\nSave to .rds formatLoad the rds file\n\n\n\nwrite_rds(heartattack_data, file = \"data/rds/heartattack.rds\")\n\n\n\n\nheartattack &lt;- read_rds(\"data/rds/heartattack.rds\")\n\n\n\n\nWe will also save a separate subset of the dataset for those who indicated ‘Yes’ for Heart Attack Occurrence.\n\nSubsetSave to .rds formatLoad the rds file\n\n\n\nyesheartattack &lt;- heartattack %&gt;%\n  filter(Heart_Attack_Occurrence == \"Yes\")\n\n\n\n\nwrite_rds(yesheartattack, file = \"data/rds/yesheartattack.rds\")\n\n\n\n\nyesheartattack &lt;- read_rds(\"data/rds/yesheartattack.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#starting-big-overview-of-heart-attack-occurrence-in-japan",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#starting-big-overview-of-heart-attack-occurrence-in-japan",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.1 Starting Big: Overview of Heart Attack Occurrence in Japan",
    "text": "5.1 Starting Big: Overview of Heart Attack Occurrence in Japan\n\n5.1.1 Heart Attack Occurrence by Age Group and Gender\nWe will first explore the distribution of heart attack occurrences across different age groups and genders in Japan. By categorizing individuals into age groups (Young, Middle-Aged, and Old), we can observe trends in heart attack prevalence, with particular focus on gender differences. This helps identify which demographic groups are more vulnerable and gives us the overview.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute percentage of Heart Attack Occurrence for each Age Category\nage_summary &lt;- yesheartattack %&gt;%\n  group_by(AgeCat) %&gt;%\n  summarise(Percentage = (n() / nrow(yesheartattack)) * 100)\n\n# Compute percentage of Heart Attack Occurrence for each Gender\ngender_summary &lt;- yesheartattack %&gt;%\n  group_by(Gender) %&gt;%\n  summarise(Percentage = (n() / nrow(yesheartattack)) * 100)\n\n# Define custom colors\ncustom_colors &lt;- c(\"Young\" = \"#cfe7af\", \"Middle-Aged\" = \"#9cc567\", \"Old\" = \"#608e24\")\n\n# Plot 1: Heart Attack Occurrence by Age Category \np1 &lt;- ggplot(age_summary, aes(x = AgeCat, y = Percentage, fill = AgeCat)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), vjust = 1.5, size = 3) +  \n  scale_fill_manual(values = custom_colors) +\n  labs(x = \"Age Category\") +  \n  theme_minimal() +\n  theme(legend.position = \"none\", plot.title = element_blank(), axis.title.y = element_blank(),axis.title.x = element_blank())  \n\n# Plot 2: Heart Attack Occurrence by Gender \np2 &lt;- ggplot(gender_summary, aes(x = Gender, y = Percentage, fill = Gender)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), vjust = 1.5, size = 3) + \n  labs(x = \"Gender\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", plot.title = element_blank(), axis.title.y = element_blank(),axis.title.x = element_blank()) \n\n# Plot 3: Heart Attack Occurrence by Age Category in Each Gender \np3 &lt;- ggbarstats(\n  data = yesheartattack,\n  x = AgeCat,\n  y = Gender \n) +\n  scale_fill_manual(values = custom_colors) +\n  theme(plot.title = element_blank()) +\n  coord_flip()\n\n(p1 + p2)/ p3 + \n  plot_layout(widths = c(1, 1, 1.5)) +  \n  plot_annotation(title = \"Heart Attack Occurrence by Age Group and Gender\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nGender and Heart Attack Vulnerability: Males are more prone to heart attacks compared to females, as observed in the dataset.\nStatistical Association between Age Category and Gender: At a 5% significance level, there is insufficient evidence to suggest a statistically significant association between Age Category and Gender in relation to heart attack occurrence. This means that, based on the data, age category and gender do not exhibit a strong statistical relationship in predicting heart attack occurrence.\nVulnerability Across Age Groups: The Young Age Group (35.3%) emerges as the most vulnerable to heart attacks across both genders.\n\nAmong females, the Old Age Group is the second most vulnerable.\nAmong males, the Middle-Aged Age Group appears to be the second most vulnerable to heart attacks.\n\n\n\n\n\n\n5.1.2 Heart Attack Occurrence by Lifestyle Factors & Medical History\nWe will first conduct Chi-squared test to test for association between each factor with heart attack occurrence to understand the relationships.\n\nBMI CategoryCholesterolStress LevelAlcohol ConsumptionDiabetes HistoryFamily History\n\n\n\nchisq.test(table(heartattack$BMICat, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(heartattack$BMICat, heartattack$Heart_Attack_Occurrence)\nX-squared = 6.3275, df = 2, p-value = 0.04227\n\n\n\n\n\nchisq.test(table(heartattack$Cholesterol, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(heartattack$Cholesterol, heartattack$Heart_Attack_Occurrence)\nX-squared = 0.79632, df = 2, p-value = 0.6716\n\n\n\n\n\nchisq.test(table(heartattack$Stress, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(heartattack$Stress, heartattack$Heart_Attack_Occurrence)\nX-squared = 2.7315, df = 2, p-value = 0.2552\n\n\n\n\n\nchisq.test(table(heartattack$Alcohol_Consumption, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(heartattack$Alcohol_Consumption, heartattack$Heart_Attack_Occurrence)\nX-squared = 3.4314, df = 3, p-value = 0.3298\n\n\n\n\n\nchisq.test(table(heartattack$Diabetes_History, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heartattack$Diabetes_History, heartattack$Heart_Attack_Occurrence)\nX-squared = 1.7, df = 1, p-value = 0.1923\n\n\n\n\n\nchisq.test(table(heartattack$Family_History, heartattack$Heart_Attack_Occurrence))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heartattack$Family_History, heartattack$Heart_Attack_Occurrence)\nX-squared = 0.03429, df = 1, p-value = 0.8531\n\n\n\n\n\nFrom the Chi-squared test results, only BMI Category with a p-value = 0.04 indicate that there is a statistically significant relationship with heart attack occurrence at the 5% significance level. We will also investigate diabetes history since it is close to being statistically significant with a p-value =0.18. I have tested all other lifestyle and medical factors and there seem to be no statistically significant relationship with heart attack.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# BMI Plot\nBMIplot &lt;- ggbarstats(\n  data = heartattack,\n  x = BMICat,\n  y = Heart_Attack_Occurrence,\n  results.subtitle = FALSE\n) +\n  labs(title = NULL) +\n  theme_minimal() +\n  theme(axis.title.y = element_blank())+\n  coord_flip()\n\n# Diabetes Plot\ndiabplot &lt;- ggbarstats(\n  data = heartattack,\n  x = Diabetes_History,\n  y = Heart_Attack_Occurrence,\n  results.subtitle = FALSE\n) +\n  labs(title = NULL) + \n  theme_minimal() +\n  theme(axis.title.y = element_blank())+\n  coord_flip()\n\nBMIplot/ diabplot + \n  plot_layout(widths = c(1, 1)) +  \n  plot_annotation(title = \"Heart Attack Occurrence by BMI and Diabetes History\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nBMI\n\nOverweight and Normal categories have a very similar distribution for both groups (those who had heart attacks and those who didn’t), suggesting that overweight individuals are still more prevalent in both groups.\n\n\n\nVulnerability to heart attack based on BMI:\n\nThe proportions of overweight and normal weight individuals are almost identical for both those who had a heart attack and those who did not.\nHowever, the significance (p-value = 0.04) tells us that there might be a real association between BMI category and the likelihood of having a heart attack, but overweight individuals do not show a notably higher proportion of heart attack occurrence in this dataset compared to other categories.\n\n\nDiabetes History\n\nAlthough there is a slight difference in the proportions of people with and without diabetes history in both heart attack groups, the test results suggest that diabetes history does not significantly contribute to the likelihood of having a heart attack in this dataset.\n\n\n\n\nLifestyle FactorsMedical History\n\n\nLifestyle factors such as smoking, alcohol consumption, physical activity, and diet quality play a significant role in heart attack occurrences. This section visualizes how these factors interact with heart attack risk, providing insights into the relative contributions of each factor. This analysis shows us the importance of lifestyle modifications in preventing heart attacks.\n\n\n\n\n\n\n\n\n\n\n\nMedical history, including conditions like diabetes, hypertension, family history of heart disease, and high cholesterol, is a critical determinant of heart attack risk. This section aims to reveal which medical conditions are most strongly associated with an increased risk. For example, individuals with a family history of heart disease or high cholesterol levels may be more likely to experience a heart attack.\n\n\n\n\n\n\n\n\n\nInsights"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#narrowing-down-risk-factors-and-their-impact",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#narrowing-down-risk-factors-and-their-impact",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Narrowing Down: Risk Factors and Their Impact",
    "text": "5.2 Narrowing Down: Risk Factors and Their Impact\nAs we delve deeper into understanding heart attack occurrence, it’s essential to focus on the specific risk factors that influence this outcome. This section aims to narrow our focus from a broad overview of heart attacks to the key lifestyle and health factors that directly contribute to their occurrence. By investigating these factors in more detail, we aim to uncover how individual behaviors, medical histories, and other characteristics interact to influence heart attack risk.\n\n5.2.1 Smoking’s Impact on Heart Attack Occurrence by Age\nSmoking has long been established as one of the most significant risk factors for heart disease, and understanding its impact across different age groups is crucial for targeted interventions. Age plays a vital role in how smoking affects heart health, with younger and older individuals potentially experiencing different risks due to variations in metabolism, vascular health, and overall lifestyle. By examining smoking’s influence on heart attack occurrence across various age groups, we can gain a better understanding of which populations are most vulnerable.\nWe will do this by calculating the rate of heart attacks occurring in each group. For instance, Number of Heart Attacks in YoungSmokers/ Total Number of YoungSmokers.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\n\n\n\n\n\n\n5.2.2 Diabetes & Hypertension Impact by Age (X)\n\n\n5.2.3 BMI vs. Heart Attack with Physical Activity Levels\n\nBMI Distribution (Boxplot + Violin Plot)\n\n\n\n\n5.2.4 Stress vs. Heart Attack by Gender and Region\n\nBy GenderBy Region\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nAt lower stress levels (0-1, 1-2), the proportions are relatively high for both genders (11-12%), with males having slightly higher values.\nAt the highest stress level (9-10), females have a noticeably higher proportion (12.01%) compared to males (10.45%). This suggests that extreme stress levels might have a higher association with heart attacks in females compared to males.\nAt lower stress levels (0-1, 1-2), rural areas show a higher proportion of heart attack occurrences than urban areas.\nAt the highest stress level (9-10), urban areas show a higher proportion of heart attack occurrences (11.55%) compared to rural areas (10.42%), suggesting that lower stress levels are associated with more heart attack occurrences in rural areas, while higher stress levels have a greater impact in urban areas.\n\n\n\n\n\n5.2.5 Heart Rate & BP Comparison\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Diastolic_BP,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n5.2.6 Cholesterol Level\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Heart_Rate,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = heartattack,\n  x = Heart_Attack_Occurrence, \n  y = Cholesterol_Level,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\ncho &lt;- heartattack %&gt;% \n  mutate(Cho_bins = cut(Cholesterol_Level, \n                        breaks = c(80, 150, 200, 240, 300),  \n                        labels = c(\"Low\", \"Desirable\", \"Borderline High\", \"High\"),\n                        include.lowest = TRUE))\n\nggbarstats(cho, \n           x = Cho_bins, \n           y = Heart_Attack_Occurrence)\n\n\n\n\n\n\n\n\n\nggplot(heartattack, aes(x = Gender_HeartAttack_Interaction, y = Cholesterol_Level, fill = Gender)) +\n  geom_violin(trim = FALSE, alpha = 0.5) +  \n  geom_boxplot(width = 0.2, color = \"black\", alpha = 0.7) +  \n  labs(x = \"Gender & Heart Attack Occurrence\", y = \"Stress Level\",\n       title = \"Distribution of Stress Levels by Gender and Heart Attack Occurrence\") +\n  scale_fill_manual(values = c(\"Female\" = \"#e67ea2\", \"Male\" = \"#1f78b4\")) +  \n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/first.html#clinical-insights",
    "href": "Take-home_Ex/Take-home_Ex01/first.html#clinical-insights",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.3 Clinical Insights",
    "text": "5.3 Clinical Insights\n\n5.3.1 Correlation between BMI and Heart Attack\n\n\n5.3.2 Blood Pressure vs. Heart Rate Among Heart Attack Patients (Regression)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-deeper",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-deeper",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Zooming in Deeper",
    "text": "5.2 Zooming in Deeper\nTo gain a deeper understanding of heart attack occurrence, it is crucial to focus on the specific risk factors that contribute to this outcome. This section narrows the scope from a general overview of heart attacks to the key health factors that directly influence their occurrence. By examining these factors more closely, we aim to uncover how individual behaviors, medical histories, and other characteristics interact to shape heart attack risk. Therefore from this point onwards, we will focus on the subset of the dataset who indicated “Yes” for having experienced heart attack.\n\n5.2.1 Vulnerability in Young Individuals: Focusing on BMI and Stress\nIn this section, we delve deeper into the factors influencing heart attack risk among young individuals, as this age group has the highest prevalence of heart attack cases across both genders. As identified in section 5.1.2, BMI plays a crucial role in heart attack occurrences, making it one of the most significant risk factors. Therefore, we now narrow our focus on the distribution of BMI categories within this young demographic, as it offers vital insights into how body weight and composition influence heart attack risk among younger populations.\nFurthermore, we examine the interplay between stress levels and BMI, particularly within the “Overweight” category. Individuals classified as overweight may face an increased vulnerability to stress-related health risks, such as heart attacks. By analyzing how stress levels (Low, Medium, and High) are distributed within the Overweight BMI category, we gain a clearer understanding of how stress contributes to heart attack risk for this group.\nThe decision to focus specifically on the “Overweight” BMI category is driven by its higher prevalence in the data, which provides a more robust and statistically meaningful foundation for analysis. By concentrating on this group, we are able to explore a critical intersection of BMI and stress, which are significant contributors to heart attack occurrences in young individuals.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyoung_data &lt;- yesheartattack %&gt;% filter(AgeCat == \"Young\")\n\n# Calculate the proportion of each BMI category in young_data\nbmi_proportion_data &lt;- young_data %&gt;%\n  count(BMICat) %&gt;%\n  mutate(Proportion = n / sum(n))\n\n# Distribution of BMI in Young group\nbmi_young &lt;- ggplot(bmi_proportion_data, aes(x = BMICat, y = Proportion, fill = BMICat)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), vjust = 1.5, size = 4) + \n  labs(\n       y = \"Proportion\") +  \n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Underweight\" = \"#9ddcf2\", \"Normal\" = \"#83bace\", \"Overweight\" = \"#0d8ab7\")) +  \n  theme_minimal() +\n  theme(legend.position = \"none\", \n        axis.text.x = element_text(angle = 45, hjust = 1, size = 12), \n        axis.title = element_text(size = 14, face = \"bold\"), \n        plot.title = element_blank(),\n        axis.title.x = element_blank())  \n\n# Calculate the proportion of stress levels within the overweight group\nstress_overweight &lt;- young_data %&gt;%\n  count(Stress) %&gt;%\n  mutate(Proportion = n / sum(n))  \n\nstress_overweight$Stress &lt;- factor(stress_overweight$Stress, levels = c(\"High\", \"Medium\", \"Low\"))\n\n# Create the stacked bar chart for just overweight\nstress_ow &lt;- ggplot(stress_overweight, aes(x = \"Overweight\", y = Proportion, fill = Stress)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), position = position_stack(vjust = 0.5), size = 4) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Low\" = \"#9cc567\", \"Medium\" = \"#83bace\", \"High\" = \"#f7a8b8\")) +\n  labs(x = NULL, y = \"Proportion\", title = NULL) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 12), \n        axis.title.y = element_blank())\n\nbmi_young + stress_ow +\n  plot_layout(widths = c(2, 1)) + \n  plot_annotation(title = \"Proportion of BMI and Stress Level in Young Individuals who had a Heart Attack\")\n\n\n\n\n\n\n\n\n\n\nInsight\n\n\n\nIn young individuals, the Overweight BMI category with Medium stress levels shows the highest proportion of heart attack cases. This suggests a strong correlation between being overweight and experiencing medium levels of stress, which may exacerbate the likelihood of heart attacks. The visualization emphasizes the need for targeted interventions focusing on stress management and weight control in this demographic.\n\n\n\n\n5.2.2 Stress Levels in Gender and Regions\nExploring the influence of both gender and region (urban vs. rural) on heart attack occurrence among overweight individuals with varying stress levels can provide valuable insights into disparities in cardiovascular risk. By examining how gender and region interact with different stress levels, we aim to uncover any significant patterns that may indicate higher vulnerability to heart attacks. Specifically, we will focus on comparing the Medium Stress group (which shows the highest proportion of heart attack cases) with the High Stress group to determine whether stress levels amplify the effects of gender and region in heart attack risk.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter the data for Overweight individuals with Stress levels\nregion_stress_overweight &lt;- yesheartattack %&gt;%\n  filter(BMICat == \"Overweight\" & Stress %in% c(\"High\", \"Medium\"))\n\n# Calculate the proportion of Stress levels by Region\nproportion_region_stress &lt;- region_stress_overweight %&gt;%\n  group_by(Region, Stress) %&gt;%\n  summarise(Proportion = n() / nrow(region_stress_overweight) * 100)\n\n# Region plot\nregions&lt;- ggplot(proportion_region_stress, aes(x = Region, y = Proportion, fill = Region)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1.5, size = 3) +\n  labs(x = \"Region\", y = \"Proportion (%)\") +\n  scale_fill_manual(values = c(\"Rural\" = \"#9cc567\", \"Urban\" = \"#e79251\")) + \n  facet_wrap(~ Stress, ncol = 2) + \n  theme_minimal()+\n  theme(axis.title.y = element_blank(),\n        plot.title=element_blank())\n\n# Calculate the proportion within each Stress level group\nproportion_heartattack &lt;- high_medium_stress_overweight_yes %&gt;%\n  group_by(Stress, Gender) %&gt;%\n  summarise(Proportion = n() / nrow(high_medium_stress_overweight_yes) * 100)\n\n# Gender plot\ngender&lt;- ggplot(proportion_heartattack, aes(x = Gender, y = Proportion, fill = Gender)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1.5, size = 3) +\n  labs(x = \"Gender\", y = \"Proportion of Heart Attack Cases\") +\n  scale_fill_manual(values = c(\"Female\" = \"#f7a8b8\", \"Male\" = \"#83bace\")) + \n  facet_wrap(~ Stress, ncol = 2) + \n  theme_minimal()+\n  theme(axis.title.y = element_blank())\n\n# Filter the data for Overweight individuals\noverweight_data &lt;- yesheartattack %&gt;%\n  filter(BMICat == \"Overweight\")\n\n# Calculate the proportion of heart attack cases by Gender and Region\nproportion_heartattack_group &lt;- overweight_data %&gt;%\n  group_by(Gender, Region) %&gt;%\n  summarise(Proportion = n() / nrow(overweight_data) * 100)\n\n# Create the bar plot\ngender_reg &lt;- ggplot(proportion_heartattack_group, aes(x = interaction(Gender, Region), y = Proportion, fill = interaction(Gender, Region))) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1, size = 3,hjust=1.3) +\n  labs(x = \"Gender-Region Group\", y = \"Proportion of Heart Attack Cases (%)\", \n       title = \"Vulnerability to Heart Attacks by Gender and Region in Overweight Individuals\") +\n  scale_fill_manual(values = c(\"Male.Urban\" = \"#0d8ab7\", \"Female.Urban\" = \"#e78090\", \"Male.Rural\" = \"#83bace\", \"Female.Rural\" = \"#f0c6c7\")) +\n  theme_minimal()+\n  theme(axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        plot.title = element_text(hjust = 0.5))+\n  coord_flip()\n\n\n (gender + regions)/gender_reg + \n  plot_annotation(title = \"Proportion of HeartAttack among Stress Levels by Gender and Region\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nAmong individuals with Medium and High stress levels, males appear to be more susceptible to heart attacks compared to females, indicating a possible gender-based disparity in how stress influences cardiovascular health. This suggests that men in these stress categories may face a heightened risk of heart disease due to stress.\nIndividuals residing in urban areas are generally more vulnerable to heart attacks than their rural counterparts, regardless of their stress level.\nNotably, the group most at risk is urban-dwelling males, with a heart attack proportion of 36%. They are followed by urban females, with 33.2%. These findings emphasize the combined effect of gender and urban living on heart attack vulnerability, highlighting a need for targeted interventions for males, particularly in urban settings.\n\n\n\n\n\n5.2.3 Does Diet Quality and Cholesterol Level Matter?\nBuilding on the previous analysis of gender/region and its impact on heart attack occurrence, it is also crucial to explore the relationship between diet quality and cholesterol levels in the overweight category. Diet quality plays a significant role in influencing cholesterol levels, which in turn, affects the likelihood of heart attacks (Jung et al., 2022). By examining how poor and good diet quality influence cholesterol levels in overweight individuals, we aim to understand how dietary habits contribute to the risk of heart attacks in this group. This analysis will help uncover whether poor diet quality, characterized by higher cholesterol levels, serves as an additional risk factor for heart attacks in overweight individuals, potentially compounding the effects of other health conditions such as stress and gender.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter data for Overweight and Normal BMI groups\nbmi_compare &lt;- yesheartattack %&gt;%\n  filter(BMICat %in% c(\"Overweight\", \"Normal\"))\n\n# Summarize Diet Quality proportions\ndiet_proportion &lt;- bmi_compare %&gt;%\n  count(BMICat, Diet_Quality) %&gt;%\n  group_by(BMICat) %&gt;%\n  mutate(Proportion = n / sum(n))\n\n# Stacked Bar Chart for Diet Quality\ndiet_plot &lt;- ggplot(diet_proportion, aes(x = BMICat, y = Proportion, fill = Diet_Quality)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), \n            position = position_stack(vjust = 0.5), size = 3) +\n  labs(title = \"Comparison of Diet Quality by BMI Category\",\n       x = NULL, y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Poor\" = \"#d73027\", \"Average\" = \"#fc8d59\", \"Good\" = \"#91cf60\")) +\n  theme_minimal() +\n  coord_flip() +\n  theme(plot.margin = margin(0, 30, 0, 0),\n        axis.title.x = element_blank())\n\n\n# Filter data for Poor and Good Diet Quality groups\ndiet_quality_compare &lt;- yesheartattack %&gt;%\n  filter(Diet_Quality %in% c(\"Poor\", \"Good\"))\n\n# Calculate median, 25th percentile, and 75th percentile for each Diet Quality group\ncholesterol_stats &lt;- diet_quality_compare %&gt;%\n  group_by(Diet_Quality) %&gt;%\n  summarise(\n    median = median(Cholesterol_Level, na.rm = TRUE),\n    p25 = quantile(Cholesterol_Level, 0.25, na.rm = TRUE),\n    p75 = quantile(Cholesterol_Level, 0.75, na.rm = TRUE)\n  )\n\n# Violin Plot for Cholesterol Levels by Diet Quality\ncholesterol_violin &lt;- ggplot(diet_quality_compare, aes(x = Diet_Quality, y = Cholesterol_Level, fill = Diet_Quality)) +\n  geom_violin(alpha = 0.7) +  # Violin plot for distribution\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +  # Small boxplot inside violin\n  labs(x = NULL, y = \"Cholesterol Level (mg/dL)\") +\n  scale_fill_manual(values = c(\"Poor\" = \"#d73027\", \"Good\" = \"#91cf69\")) +\n  theme_minimal() +\n  # Add text labels for median, 25th, and 75th percentiles\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = median, label = sprintf(\"Median: %.1f\", median)), \n            color = \"black\", vjust = -1.5, size = 2) +\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = p25, label = sprintf(\"%.1f\", p25)), \n            color = \"black\", vjust = 1.8, size = 2) +\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = p75, label = sprintf(\"%.1f\", p75)), \n            color = \"black\", vjust = 1.8, size = 2) +\n  coord_flip()+\n  guides(fill = \"none\")\n\n# Density Plot for Cholesterol Levels by Diet Quality\ncholesterol_density_data &lt;- yesheartattack %&gt;%\n  filter(Diet_Quality %in% c(\"Poor\", \"Good\")) %&gt;%\n  ggplot(aes(x = Cholesterol_Level, color = Diet_Quality)) +\n  geom_density(size = 1.2) +  # Line density plot\n  labs(title = \"Cholesterol Levels by Diet Quality\",\n       x = \"Cholesterol Level (mg/dL)\", y = \"Density\",\n       color = \"Diet Quality\") +\n  scale_color_manual(values = c(\"Poor\" = \"#d73027\", \"Good\" = \"#91cf60\")) +\n  theme_minimal() +\n  theme(legend.position = c(0, 1),           \n        legend.justification = c(0, 1),       \n        legend.title = element_blank(),  \n        plot.title = element_text(size = 13)) \n\n\ndiet_plot/(cholesterol_density_data + cholesterol_violin)+\n  plot_layout(widths = c(0.4, 2), heights = c(0.5, 2))\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nPoor diet quality is linked to a higher proportion of heart attack cases, with 21% of individuals in the overweight category experiencing heart attacks compared to 18% in the normal weight category. This suggests that individuals with poor diet quality in the overweight group are at a slightly higher risk of heart attacks.\nCholesterol levels tend to be more concentrated around the median in individuals with poor diet quality, indicating a higher density of cholesterol around the middle range. In contrast, good diet quality shows a more even spread of cholesterol levels.\nIndividuals with poor diet quality generally have slightly higher cholesterol levels, with a distribution skewed towards higher values, indicating a potential risk for cardiovascular diseases. In contrast, good diet quality tends to have a more balanced cholesterol distribution.\nThese factors suggest that elevated cholesterol levels due to poor diet quality may contribute to the increased heart attack risk observed in the overweight group."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#boxplot",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#boxplot",
    "title": "In-class Exercise 4",
    "section": "3.1 Boxplot",
    "text": "3.1 Boxplot\n\nData and Aes block: Include data and mapping the dimensions(x/y)\nAdd in geom after +\n\n\nggplot(exam,\n       aes(x= ENGLISH,\n           y= CLASS)) +\n    geom_boxplot()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#density-ridges",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#density-ridges",
    "title": "In-class Exercise 4",
    "section": "3.2 Density Ridges",
    "text": "3.2 Density Ridges\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#halfeye",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#halfeye",
    "title": "In-class Exercise 4",
    "section": "3.3 Halfeye",
    "text": "3.3 Halfeye\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#two-sample-mean-test-ggbetweenstats-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#two-sample-mean-test-ggbetweenstats-method",
    "title": "In-class Exercise 4",
    "section": "4.1 Two-sample mean test: ggbetweenstats() method",
    "text": "4.1 Two-sample mean test: ggbetweenstats() method\n\nnp - nonparametric for Non Normal Distribution\nAssuming unequal variance\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-way-anova-test-ggbetweenstats-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-way-anova-test-ggbetweenstats-method",
    "title": "In-class Exercise 4",
    "section": "4.2 One way ANOVA test: ggbetweenstats() method",
    "text": "4.2 One way ANOVA test: ggbetweenstats() method\n\np- for Normal distribution\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-association-dependence-ggbarstats-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-association-dependence-ggbarstats-method",
    "title": "In-class Exercise 4",
    "section": "4.3 Significant test of Association (Dependence): ggbarstats() method",
    "text": "4.3 Significant test of Association (Dependence): ggbarstats() method\n\nCons: can’t really test association with ggstatsplot so make a stacked bar chart with 100% proportion\n\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\n\n\n\nPackages UsedCode\n\n\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\ntidyverse: namely: readr, dplyr and tidyr\n\n\n\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\n\nImport the data using the code chunk below\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\nNext, we will use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "",
    "text": "Packages UsedCode\n\n\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\ntidyverse: namely: readr, dplyr and tidyr\n\n\n\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "",
    "text": "Import the data using the code chunk below\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\nNext, we will use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.1 Installing and Launching R Packages",
    "text": "2.1 Installing and Launching R Packages\n\npacman::p_load(corrplot, corrgram, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-data",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.2 Importing The Data",
    "text": "2.2 Importing The Data\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlations-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlations-matrix-pairs-method",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.3 Building Correlations Matrix: pairs() method",
    "text": "2.3 Building Correlations Matrix: pairs() method\n\n2.3.1 Building a basic correlation matrix\nTo map a 11 by 11 matrix of scatterplots, the following code will be used.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nNow, we will use columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n2.3.2 Drawing the lower corner\nA correlation matrix is symmetric. It is common practice to show either upper or lower corner only. To show the lower half, we will use the following code chunk.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n2.3.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.4 Visualising Correlation Matrix: ggcormat()",
    "text": "2.4 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\n\n2.4.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\nYou may even change the colors on the basic correlation matrix.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggplot.component = list(\n    ggplot2::scale_fill_gradient2(\n      low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0\n    )\n  )\n)\n\n\n\n\n\n\n\n\nWe can add title and subtitle like this.\n\nCodeThings to Learn\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\n\n\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.5 Building multiple plots",
    "text": "2.5 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to note!\n\n\n\n\nTo build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.6 Visualising Correlation Matrix using corrplot Package",
    "text": "2.6 Visualising Correlation Matrix using corrplot Package\n\n2.6.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\nDarker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n2.6.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. This can be changed by using the method as shown in the code below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n\n2.6.3 Working with layout\ncorrplot() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type = \"lower\", \n         diag = FALSE, \n         tl.col = \"black\",        # Color of text labels\n         tl.pos = \"lt\",           # Position of text labels\n         tl.cex = 1.2,            # Size of text labels\n         tl.offset = 0.5,         # Text label offset\n         cl.pos = \"b\",            # Position of color legend\n         cl.cex = 1.0,            # Size of color legend text\n         cl.offset = 0.5,         # Offset of color legend\n         addCoef.col = \"red\",     # Adds correlation coefficients in red\n         number.cex = 0.8,        # Size of correlation numbers\n         col = colorRampPalette(c(\"red\", \"white\", \"blue\"))(200) # Custom color gradient\n)\n\n\n\n\n\n\n\n\n\n\n2.6.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n2.6.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk b\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\nThe corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\n\n2.6.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n2.6.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrgram-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrgram-package",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "2.7 Visualising Correlation Matrix using corrgram Package",
    "text": "2.7 Visualising Correlation Matrix using corrgram Package\nIn the same way, we need to compute the correlation matrix of wine data frame for corrgram package as well.\nWe will use the following code.\n\ncorrgram(wine, \n         order = TRUE, \n         lower.panel = panel.shade, upper.panel = panel.ellipse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "3.1 Installing and Launching R Packages",
    "text": "3.1 Installing and Launching R Packages\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "3.2 Importing and Preparing The Data Set",
    "text": "3.2 Importing and Preparing The Data Set\nThe original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "3.3. Static Heatmap",
    "text": "3.3. Static Heatmap\nR packages and functions can be used to drawing static heatmaps,:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\n\n3.3.1 heatmap() of R Stats\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRed cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\n\n\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "3.4 Creating Interactive Heatmap",
    "text": "3.4 Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\n\n3.4.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nBasic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\n\n\n3.4.2 Data trasformation\nVariables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nPercentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nScaling: It works well when variables have different magnitudes but share a similar underlying distribution. Best for data that follows a Gaussian (normal) distribution and needs to be compared in terms of deviation from the mean.\nNormalizing:Preserves the shape of the original distribution, making it easy to compare variables with different units and scales.Best for data that is not normally distributed and requires a common scale while keeping the relative distances between observations intact.\nPercentize: Helps in ranking values while ensuring that they are comparable without making assumptions about their distribution. Best for when the focus is on relative rankings rather than absolute differences.\n\n\n\n\n\n3.4.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\n\nManual approach\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\nNow there are 3 Clusters shown on the right side with three different colors.\n\n\n\n3.4.4 Seriation\n\n\n\n\n\n\nImportant\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\n\n\nOptimal Leaf Ordering (OLO): This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n3.4.5 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n3.4.6 The finishing touch\n\nThe ExplanationThe Code\n\n\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-vulnerability-in-young-individuals",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-vulnerability-in-young-individuals",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.2 Zooming in: Vulnerability in Young Individuals",
    "text": "5.2 Zooming in: Vulnerability in Young Individuals\nTo gain a deeper understanding of heart attack occurrence, it is crucial to focus on the specific risk factors that contribute to this outcome. This section narrows the scope from a general overview of heart attacks to the key health factors that directly influence their occurrence. By examining these factors more closely, we aim to uncover how individual behaviors, medical histories, and other characteristics interact to shape heart attack risk.\n\n\n\n\n\n\nImportant\n\n\n\nTherefore, from this point onwards, we will focus on the subset of the dataset who indicated “Yes” for having experienced heart attack.\n\n\n\n5.2.1 Focusing on Stress and BMI\nIn this section, we take a closer look at the role of stress in heart attack risk among young individuals, as this age group has the highest prevalence of heart attack cases across both genders. As identified in section 5.1.1, stress is a significant factor in heart attack occurrences, making it a key area of focus. To further understand its impact, we examine how stress levels (Low, Medium, and High) are distributed across different BMI categories within the young demographic.\nFurthermore, we examine the interplay between stress levels and BMI, particularly within the “Overweight” category. Individuals classified as overweight may face an increased vulnerability to stress-related health risks, such as heart attacks. By analyzing how stress levels are distributed within the Overweight BMI category, we gain a clearer understanding of how stress contributes to heart attack risk for this group. While BMI itself was not found to be a significant predictor, it is important to explore whether stress interacts differently within this subgroup.\nThe decision to focus specifically on the “Overweight” BMI category is driven by its higher prevalence in the data, which provides a more robust and statistically meaningful foundation for analysis. By concentrating on this group, we are able to explore a critical intersection of BMI and stress, which are significant contributors to heart attack occurrences in young individuals.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyoung_data &lt;- yesheartattack %&gt;% filter(AgeCat == \"Young\")\n\n# Calculate the proportion of each BMI category in young_data\nbmi_proportion_data &lt;- young_data %&gt;%\n  count(BMICat) %&gt;%\n  mutate(Proportion = n / sum(n))\n\n# Distribution of BMI in Young group\nbmi_young &lt;- ggplot(bmi_proportion_data, aes(x = BMICat, y = Proportion, fill = BMICat)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), vjust = 1.5, size = 4) + \n  labs(\n       y = \"Proportion\") +  \n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Underweight\" = \"#9ddcf2\", \"Normal\" = \"#83bace\", \"Overweight\" = \"#0d8ab7\")) +  \n  theme_minimal() +\n  theme(legend.position = \"none\", \n        axis.text.x = element_text(angle = 45, hjust = 1, size = 12), \n        axis.title = element_text(size = 14, face = \"bold\"), \n        plot.title = element_blank(),\n        axis.title.x = element_blank())  \n\n# Filter young individuals who are overweight\noverweight_young &lt;- young_data %&gt;% filter(BMICat == \"Overweight\")\n\n# Calculate the proportion of stress levels within the overweight group\nstress_overweight &lt;- overweight_young %&gt;%\n  count(Stress) %&gt;%\n  mutate(Proportion = n / sum(n))  \n\nstress_overweight$Stress &lt;- factor(stress_overweight$Stress, levels = c(\"High\", \"Medium\", \"Low\"))\n\n# Create the stacked bar chart for just overweight\nstress_ow &lt;- ggplot(stress_overweight, aes(x = \"Overweight\", y = Proportion, fill = Stress)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), position = position_stack(vjust = 0.5), size = 4) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Low\" = \"#9cc567\", \"Medium\" = \"#83bace\", \"High\" = \"#f7a8b8\")) +\n  labs(x = NULL, y = \"Proportion\", title = NULL) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 12), \n        axis.title.y = element_blank())\n\nbmi_young+ stress_ow +\n  plot_layout(widths = c(2, 1)) + \n  plot_annotation(title = \"Proportion of Stress Level and BMI in Young Individuals who had a Heart Attack\")\n\n\n\n\n\n\n\n\n\n\nInsight\n\n\n\nIn young individuals, the Overweight BMI category with Medium stress levels shows the highest proportion of heart attack cases. This suggests a strong correlation between being overweight and experiencing medium levels of stress, which may exacerbate the likelihood of heart attacks. The visualization emphasizes the need for targeted interventions focusing on stress management and weight control in this particular demographic.\n\n\n\n\n5.2.2 Stress Levels in Gender and Regions\nExploring the influence of both gender and region (urban vs. rural) on heart attack occurrence among overweight individuals with varying stress levels can provide valuable insights into disparities in cardiovascular risk. By examining how gender and region interact with different stress levels, we aim to uncover any significant patterns that may indicate higher vulnerability to heart attacks. Specifically, we will focus on comparing the Medium Stress group (which shows the highest proportion of heart attack cases) with the High Stress group to determine whether stress levels amplify the effects of gender and region in heart attack risk.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter the data for Overweight individuals with Stress levels\nregion_stress_overweight &lt;- yesheartattack %&gt;%\n  filter(BMICat == \"Overweight\" & Stress %in% c(\"High\", \"Medium\"))\n\n# Calculate the proportion of Stress levels by Region\nproportion_region_stress &lt;- region_stress_overweight %&gt;%\n  group_by(Region, Stress) %&gt;%\n  summarise(Proportion = n() / nrow(region_stress_overweight) * 100)\n\n# Region plot\nregions&lt;- ggplot(proportion_region_stress, aes(x = Region, y = Proportion, fill = Region)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1.5, size = 3) +\n  labs(x = \"Region\", y = \"Proportion (%)\") +\n  scale_fill_manual(values = c(\"Rural\" = \"#9cc567\", \"Urban\" = \"#e79251\")) + \n  facet_wrap(~ Stress, ncol = 2) + \n  theme_minimal()+\n  theme(axis.title.y = element_blank(),\n        plot.title=element_blank())\n\n# Calculate the proportion within each Stress level group\nproportion_heartattack &lt;- high_medium_stress_overweight_yes %&gt;%\n  group_by(Stress, Gender) %&gt;%\n  summarise(Proportion = n() / nrow(high_medium_stress_overweight_yes) * 100)\n\n# Gender plot\ngender&lt;- ggplot(proportion_heartattack, aes(x = Gender, y = Proportion, fill = Gender)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1.5, size = 3) +\n  labs(x = \"Gender\", y = \"Proportion of Heart Attack Cases\") +\n  scale_fill_manual(values = c(\"Female\" = \"#f7a8b8\", \"Male\" = \"#83bace\")) + \n  facet_wrap(~ Stress, ncol = 2) + \n  theme_minimal()+\n  theme(axis.title.y = element_blank())\n\n# Filter the data for Overweight individuals\noverweight_data &lt;- yesheartattack %&gt;%\n  filter(BMICat == \"Overweight\")\n\n# Calculate the proportion of heart attack cases by Gender and Region\nproportion_heartattack_group &lt;- overweight_data %&gt;%\n  group_by(Gender, Region) %&gt;%\n  summarise(Proportion = n() / nrow(overweight_data) * 100)\n\n# Create the bar plot\ngender_reg &lt;- ggplot(proportion_heartattack_group, aes(x = interaction(Gender, Region), y = Proportion, fill = interaction(Gender, Region))) +\n  geom_bar(stat = \"identity\", show.legend = FALSE, color = \"black\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), vjust = 1, size = 3,hjust=1.3) +\n  labs(x = \"Gender-Region Group\", y = \"Proportion of Heart Attack Cases (%)\", \n       title = \"Vulnerability to Heart Attacks by Gender and Region in Overweight Individuals\") +\n  scale_fill_manual(values = c(\"Male.Urban\" = \"#0d8ab7\", \"Female.Urban\" = \"#e78090\", \"Male.Rural\" = \"#83bace\", \"Female.Rural\" = \"#f0c6c7\")) +\n  theme_minimal()+\n  theme(axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        plot.title = element_text(hjust = 0.5))+\n  coord_flip()\n\n\n (gender + regions)/gender_reg + \n  plot_annotation(title = \"Proportion of HeartAttack among Stress Levels by Gender and Region\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nAmong individuals with Medium and High stress levels, males appear to be more susceptible to heart attacks compared to females, indicating a possible gender-based disparity in how stress influences cardiovascular health. This suggests that men in these stress categories may face a heightened risk of heart disease due to stress.\nIndividuals residing in urban areas are generally more vulnerable to heart attacks than their rural counterparts, regardless of their stress level.\nNotably, the group most at risk is urban-dwelling males, with a heart attack proportion of 36%. They are followed by urban females, with 33.2%. These findings emphasize the combined effect of gender and urban living on heart attack vulnerability, highlighting a need for targeted interventions for males, particularly in urban settings.\n\n\n\n\n\n5.2.3 Does Diet Quality and Cholesterol Level Matter?\nBuilding on the previous analysis of gender/region and its impact on heart attack occurrence, it is also crucial to explore the relationship between diet quality and cholesterol levels in the overweight category. Diet quality plays a significant role in influencing cholesterol levels, which in turn, affects the likelihood of heart attacks (Jung et al., 2022). By examining how poor and good diet quality influence cholesterol levels in overweight individuals, we aim to understand how dietary habits contribute to the risk of heart attacks in this group. This analysis will help uncover whether poor diet quality, characterized by higher cholesterol levels, serves as an additional risk factor for heart attacks in overweight individuals, potentially compounding the effects of other health conditions such as stress and gender.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Filter data for Overweight and Normal BMI groups\nbmi_compare &lt;- yesheartattack %&gt;%\n  filter(BMICat %in% c(\"Overweight\", \"Normal\"))\n\n# Summarize Diet Quality proportions\ndiet_proportion &lt;- bmi_compare %&gt;%\n  count(BMICat, Diet_Quality) %&gt;%\n  group_by(BMICat) %&gt;%\n  mutate(Proportion = n / sum(n))\n\n# Stacked Bar Chart for Diet Quality\ndiet_plot &lt;- ggplot(diet_proportion, aes(x = BMICat, y = Proportion, fill = Diet_Quality)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), \n            position = position_stack(vjust = 0.5), size = 3) +\n  labs(title = \"Comparison of Diet Quality by BMI Category\",\n       x = NULL, y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  scale_fill_manual(values = c(\"Poor\" = \"#d73027\", \"Average\" = \"#fc8d59\", \"Good\" = \"#91cf60\")) +\n  theme_minimal() +\n  coord_flip() +\n  theme(plot.margin = margin(0, 30, 0, 0),\n        axis.title.x = element_blank())\n\n\n# Filter data for Poor and Good Diet Quality groups\ndiet_quality_compare &lt;- yesheartattack %&gt;%\n  filter(Diet_Quality %in% c(\"Poor\", \"Good\"))\n\n# Calculate median, 25th percentile, and 75th percentile for each Diet Quality group\ncholesterol_stats &lt;- diet_quality_compare %&gt;%\n  group_by(Diet_Quality) %&gt;%\n  summarise(\n    median = median(Cholesterol_Level, na.rm = TRUE),\n    p25 = quantile(Cholesterol_Level, 0.25, na.rm = TRUE),\n    p75 = quantile(Cholesterol_Level, 0.75, na.rm = TRUE)\n  )\n\n# Violin Plot for Cholesterol Levels by Diet Quality\ncholesterol_violin &lt;- ggplot(diet_quality_compare, aes(x = Diet_Quality, y = Cholesterol_Level, fill = Diet_Quality)) +\n  geom_violin(alpha = 0.7) +  # Violin plot for distribution\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +  # Small boxplot inside violin\n  labs(x = NULL, y = \"Cholesterol Level (mg/dL)\") +\n  scale_fill_manual(values = c(\"Poor\" = \"#d73027\", \"Good\" = \"#91cf69\")) +\n  theme_minimal() +\n  # Add text labels for median, 25th, and 75th percentiles\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = median, label = sprintf(\"Median: %.1f\", median)), \n            color = \"black\", vjust = -1.5, size = 2) +\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = p25, label = sprintf(\"%.1f\", p25)), \n            color = \"black\", vjust = 1.8, size = 2) +\n  geom_text(data = cholesterol_stats, aes(x = Diet_Quality, y = p75, label = sprintf(\"%.1f\", p75)), \n            color = \"black\", vjust = 1.8, size = 2) +\n  coord_flip()+\n  guides(fill = \"none\")\n\n# Density Plot for Cholesterol Levels by Diet Quality\ncholesterol_density_data &lt;- yesheartattack %&gt;%\n  filter(Diet_Quality %in% c(\"Poor\", \"Good\")) %&gt;%\n  ggplot(aes(x = Cholesterol_Level, color = Diet_Quality)) +\n  geom_density(size = 1.2) +  # Line density plot\n  labs(title = \"Cholesterol Levels by Diet Quality\",\n       x = \"Cholesterol Level (mg/dL)\", y = \"Density\",\n       color = \"Diet Quality\") +\n  scale_color_manual(values = c(\"Poor\" = \"#d73027\", \"Good\" = \"#91cf60\")) +\n  theme_minimal() +\n  theme(legend.position = c(0, 1),           \n        legend.justification = c(0, 1),       \n        legend.title = element_blank(),  \n        plot.title = element_text(size = 13)) \n\n\ndiet_plot/(cholesterol_density_data + cholesterol_violin)+\n  plot_layout(widths = c(0.4, 2), heights = c(0.5, 2))\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nPoor diet quality is linked to a higher proportion of heart attack cases, with 21% of individuals in the overweight category experiencing heart attacks compared to 18% in the normal weight category. This suggests that individuals with poor diet quality in the overweight group are at a slightly higher risk of heart attacks.\nCholesterol levels tend to be more concentrated around the median in individuals with poor diet quality, indicating a higher density of cholesterol around the middle range. In contrast, good diet quality shows a more even spread of cholesterol levels.\nIndividuals with poor diet quality generally have slightly higher cholesterol levels, with a distribution skewed towards higher values, indicating a potential risk for cardiovascular diseases. In contrast, good diet quality tends to have a more balanced cholesterol distribution.\nThese factors suggest that elevated cholesterol levels due to poor diet quality may contribute to the increased heart attack risk observed in the overweight group."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#vulnerability-in-old-individuals",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#vulnerability-in-old-individuals",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.3 Vulnerability in Old Individuals",
    "text": "5.3 Vulnerability in Old Individuals\nFrom insights drawn at section 5.1.3, the least vulnerable demographic seems to be the individuals from the category “Old”. Let’s further analyze this group to understand why this might be the case.\n\n5.3.1 Stress Levels\n\n# Filter for Young and Old categories\nheartattack_filtered &lt;- yesheartattack %&gt;%\n  filter(AgeCat %in% c(\"Young\", \"Old\"))\n\nggplot(heartattack_filtered, \n       aes(x = AgeCat, \n           y = Stress_Levels)) +\n  stat_halfeye(adjust = 0.3,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               height = 2,,\n               alpha = 0.4) +  # Nudge the half-eye plot upwards for more space\n  geom_boxplot(width = .20,\n               position = position_dodge(width = 0.9)) + \n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = 0.1,\n            dotsize = 0.3,\n            alpha = 0.5) +\n  coord_flip() +\n  theme_minimal() + \n  labs(title = \"BMI Distribution by Age Category\",\n       x = \"Age Category\",\n       y = \"BMI\") +\n  scale_x_discrete(labels = c(\"Young\", \"Old\"), expand = c(0.9, 0.9)) +\n  scale_y_continuous(expand = c(0.1, 0.5))  # Increase bottom space to avoid overlap\n\n\n\n\n\n\n\n\n\n# Boxplot comparing BMI distribution between young and old individuals\nggplot(heartattack_filtered, aes(x = AgeCat, y = BMI, fill = AgeCat)) +\n  geom_boxplot() +\n  labs(title = \"BMI Distribution by Age Category\",\n       x = \"Age Category\",\n       y = \"BMI\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Young\" = \"#63b2e3\", \"Old\" = \"#f1b6b1\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-distributions",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-distributions",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.1 Visualising the Distributions",
    "text": "5.1 Visualising the Distributions\nTo begin, we first assess the distribution of heart attack occurrences in our dataset, which consists of 30,000 records. How many individuals experienced a heart attack? Is the dataset balanced in terms of heart attack cases versus non-cases?\nNext, we examine the distribution of gender—are males and females equally represented? Similarly, we analyze the regional distribution to determine whether rural and urban populations are proportionally sampled in the data.\nUnderstanding these proportions is crucial, as any significant imbalance could influence our analysis and the generalizability of our findings. By exploring these distributions, we can better assess potential biases and determine whether adjustments, such as weighting or stratified analysis, may be necessary moving forward.\nLet’s start by visualizing pie charts of the categorical variables in our full dataset.\n\n\n\n\n\n\n\n\n\nFrom the pie charts, we saw that:\n\nOnly 10% of individuals in the dataset have experienced a heart attack, while 90% have not. This suggests an imbalance in the dataset, where heart attack cases are sampled much fewer than non-cases.\nThe dataset has an equal representation of males (50%) and females (50%).This balance ensures that gender-related analyses are not biased toward one group over the other.\nThe underrepresentation of rural populations means findings may be more urban-centric unless adjustments are made. If rural populations are at different levels of heart attack risk, this imbalance may impact the generalizability of results.\nYoung age category is over represented as compared to middle-aged and old. Since this may overemphasize the vulnerabilitiy of young individuals, we will have to adjust this AgeCat variable for further analysis as shown in section 5.2.3.\nIn stress categories is the medium level is over represented as well. Since this may overemphasize the medium stress level, we will have to adjust this Stress variable for further analysis as shown in section 5.3.1."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-vulnerability-in-young-vs-old-individuals",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#zooming-in-vulnerability-in-young-vs-old-individuals",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "5.3 Zooming in: Vulnerability in Young vs Old Individuals",
    "text": "5.3 Zooming in: Vulnerability in Young vs Old Individuals\nUnderstanding heart attack vulnerability requires examining how risk factors differ across age groups. Young and old individuals present distinct physiological, behavioral, and lifestyle characteristics that influence heart attack risk. Young individuals may experience heart attacks due to factors such as stress, lifestyle habits, or underlying conditions, while older individuals often face risks associated with long-term health issues, including hypertension, cholesterol, and cardiovascular disease.\nBy focusing on these two age groups, we aim to uncover key differences in how heart attacks manifest and what factors contribute most significantly to their occurrence. This targeted approach allows us to explore whether certain risk factors, such as stress, have a stronger impact in one group over the other, ultimately providing more age-specific insights into heart attack prevention and management.\n\n5.3.1 Focusing on Stress among Heart Attack Cases\nStress is a well known contributor to heart disease, but its impact may vary depending on age. In young individuals, stressors such as work pressure, financial concerns, and lifestyle choices may lead to sudden cardiovascular strain, increasing heart attack risk. In contrast, for older individuals, chronic stress and cumulative health burdens can contribute to long-term cardiovascular deterioration.\nGiven the significance of stress in heart attack occurrences, as identified in Section 5.1.2, this section examines how stress levels differ between young and old individuals and whether these variations influence heart attack vulnerability. By analyzing these distinctions, we can better understand whether stress acts as a more immediate or gradual risk factor across different age demographics.\n\n\n\n\n\n\nAdjustment for Stress Category Imbalance\n\n\n\nAs found in section 5.1, in our dataset, the Stress category distribution is imbalanced, with the following proportions:\n\nMedium: 53%\nLow: 31%\nHigh: 16%\n\nIf we use the Stress categories as they are, the medium category would be disproportionately represented. To ensure more accurate insights and prevent overemphasis on the medium stress group, we will first analyze within each stress category before visualizing the results.\nTo achieve this, we calculate proportion of young/middle-age/old individuals within each stress group (i.e. Number of Young individuals in each Stress Category who experienced Heart Attack​/ Total Number of Heart Attack Cases in each Stress Category)\n\n\nFor this visualization, we will use ggbetweenstats() to test whether there is a significant association between age categories and stress levels. Additionally, geom_boxplot() will be used to compare stress levels between younger and older individuals, while geom_bar() from the ggplot2 package will create bar charts to display the distribution of stress levels across age categories. Finally, the patchwork package will be used to combine these plots into a cohesive and structured layout.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Compute total number of \"Yes\" Heart Attack cases in each Stress category\ntotal_stress_counts &lt;- yesheartattack %&gt;%\n  group_by(Stress) %&gt;%\n  summarise(TotalCount = n())\n\n# Count the number of \"Yes\" Heart Attack cases for each AgeCat and Stress category\nage_stress_counts &lt;- yesheartattack %&gt;%\n  filter(AgeCat %in% c(\"Young\", \"Old\")) %&gt;%\n  group_by(AgeCat, Stress) %&gt;%\n  summarise(Count = n(),.groups = \"drop\")\n\n# Join the counts with the total Stress counts to calculate normalized proportions\nnormalized_stress &lt;- age_stress_counts %&gt;%\n  left_join(total_stress_counts, by = \"Stress\") %&gt;%\n  mutate(NormalizedStress = Count / TotalCount)\n\n# Plot normalized Stress proportions for each AgeCat\nstressplot &lt;- ggplot(normalized_stress, aes(x = AgeCat, y = NormalizedStress, fill = Stress)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  \n  geom_text(aes(label = sprintf(\"%.1f%%\", NormalizedStress * 100)), \n            position = position_dodge(width = 0.8), vjust = 1.5, size = 2) +  \n  scale_fill_manual(values = c(\"Low\" = \"#ffcccc\", \"Medium\" = \"#83bace\", \"High\" = \"#608e24\")) +\n  labs(x = \"Age Category\", y = \"Normalized Stress Proportion\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        legend.title= element_text(size=7),\n        legend.text= element_text(size=5),\n        plot.title = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.x = element_blank())\n\n# Filter for Young and Old categories\nheartattack_filtered &lt;- yesheartattack %&gt;%\n  filter(AgeCat %in% c(\"Young\", \"Old\"))\n\n#Distribution of stress in Young/Old\n# Calculate the statistics\nstats &lt;- heartattack_filtered %&gt;%\n  group_by(AgeCat) %&gt;%\n  summarise(\n    median = median(Stress_Levels),\n    Q1 = quantile(Stress_Levels, 0.25),\n    Q3 = quantile(Stress_Levels, 0.75),\n    .groups = \"drop\"\n  )\n\n# Boxplot\nstress_box&lt;- ggplot(heartattack_filtered, aes(x = AgeCat, y = Stress_Levels, fill = AgeCat)) +\n  geom_boxplot() +\n  geom_text(data = stats, \n            aes(x = AgeCat, \n                y = median, \n                label = paste(\"Median:\", round(median, 2))), \n            position = position_nudge(y = 0.5), size = 2) +\n  geom_text(data = stats, \n            aes(x = AgeCat, \n                y = Q1, \n                label = paste(\"25th Percentile:\", round(Q1, 2))), \n            position = position_nudge(y = -0.5), size = 2) +\n  geom_text(data = stats, \n            aes(x = AgeCat, \n                y = Q3, \n                label = paste(\"75th Percentile:\", round(Q3, 2))), \n            position = position_nudge(y = 0.5), size = 2) +\n  labs(\n       x = \"Age Category\",\n       y = \"Stress Level\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Young\" = \"#ffe372\", \"Old\" = \"#e5ae85\"))+\n  theme(legend.position = \"none\",\n        plot.title = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.x = element_blank())\n\n\n#Anova\nanova_stress &lt;- ggbetweenstats(\n  data = yesheartattack,\n  x = AgeCat, \n  y = Stress_Levels,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)+\n  theme(axis.title.x = element_blank())\n\nanova_stress+stress_box+stressplot + \n  plot_layout(widths = c(1, 0.8, 0.8)) +  \n  plot_annotation(title = \"Stress Level of Heart Attack Cases by Age Category\")\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nWhen conducting a Welch’s one-way ANOVA test to examine the relationship between Stress levels and Age categories among heart attack patients, the test resulted in a p-value of 0.02, indicating a significant difference in stress levels between young and old patients. On average, older patients had a higher stress level (mean = 5.07) compared to younger patients (mean = 4.83).\nBoxplot analysis further supports this finding, showing that older patients have a higher median stress level of 5.19, whereas younger patients have a median of 4.83. Additionally, the interquartile range (IQR) is higher for older individuals, meaning both the 25th and 75th percentiles of stress levels are elevated in this group.\nWhen examining stress categories, young heart attack patients were most commonly found in the Low Stress category, with 38.2% of cases. In contrast, older individuals had a greater proportion of heart attack cases in the Medium and High Stress categories. This aligns with the boxplot observations, reinforcing that older heart attack patients generally experience higher stress levels compared to younger patients.\n\n\n\n\n\n5.3.2 Stress Levels in Systolic vs Diastolic Blood Pressure\nBlood pressure (BP) is a critical indicator of cardiovascular health, with fluctuations often linked to stress levels. Research has shown that prolonged exposure to stress can contribute to blood pressure dysregulation, increasing the risk of cardiovascular events, including heart attacks (Gordon & Mendes, 2021).\nSystolic blood pressure (SBP) measures the pressure exerted on artery walls when the heart contracts, while diastolic blood pressure (DBP) reflects the pressure during heart relaxation. Understanding the relationship between stress and both BP components helps assess how stress-induced cardiovascular responses vary between individuals.\nWe will visualize both SBP and DBP using geom_boxplot() from the ggplot2 package, with the plots faceted by stress levels. This approach allows for a clear comparison of different age categories within each stress level.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Boxplot to compare diastolic BP distribution by stress level and age group\ndia &lt;- ggplot(yesheartattack, aes(x = AgeCat, y = Diastolic_BP, fill = AgeCat)) +\n  geom_boxplot() +\n  facet_wrap(~ Stress) +  # Remove scales = 'free' to make y-axis same for all facets\n  stat_summary(fun = median, geom = \"text\", aes(label = round(..y.., 2)), \n               vjust = -0.5, color = \"black\", size = 3) +  # Add median text\n  labs(title = \"Distribution of Diastolic BP and Systolic BP by Stress Level and Age Group\",\n       x = \"Age Group\",\n       y = \"Diastolic BP (mmHg)\") +\n  scale_fill_manual(values = c(\"Young\" = \"#ffde59\", \"Middle-Aged\" = \"#9cc567\", \"Old\" = \"#fcadb9\")) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        legend.position = \"none\")\n\n# Boxplot to compare systolic BP distribution by stress level and age group\nsys &lt;- ggplot(yesheartattack, aes(x = AgeCat, y = Systolic_BP, fill = AgeCat)) +\n  geom_boxplot() +\n  facet_wrap(~ Stress) +  # Remove scales = 'free' to make y-axis same for all facets\n  stat_summary(fun = median, geom = \"text\", aes(label = round(..y.., 2)), \n               vjust = -0.5, color = \"black\", size = 3) +  # Add median text\n  labs(x = \"Age Group\",\n       y = \"Systolic BP (mmHg)\") +\n  scale_fill_manual(values = c(\"Young\" = \"#ffde59\", \"Middle-Aged\" = \"#9cc567\", \"Old\" = \"#fcadb9\")) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        plot.title = element_blank(),\n        strip.text = element_blank(),  # Removes \"Low,\" \"Medium,\" \"High\" labels\n        legend.position = \"none\")\n\ndia / sys\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nBoth SBP and DBP appear to be relatively stable across stress levels, with only slight variations.\nOlder individuals tend to have higher median SBP and DBP, likely due to reduced arterial elasticity and increased vascular resistance with aging.\nDiastolic BP:\n\nYoung individuals exhibited a decline in median DBP with increasing stress, suggesting possible acute stress adaptation or a physiological response.\nOlder individuals showed a slight increase in DBP with higher stress, which could be attributed to chronic stress effects.\n\nSystolic BP:\n\nYoung individuals also show a slight decrease in SBP under high stress, reinforcing the idea that they may have better cardiovascular adaptability.\nOlder individuals see a moderate rise in SBP with high stress, which aligns with the DBP trend, suggesting stress-induced hypertension risk.\n\nMiddle-aged individuals exhibit the most stable blood pressure across stress levels, possibly due to adaptation mechanisms.\nDiastolic BP shows a stronger age-dependent variation under stress than Systolic BP.\n\n\n\n\n\n5.3.3 Stress Levels in Diastolic Blood Pressure\nAmong the two blood pressure metrics, diastolic BP demonstrated a stronger and statistically significant correlation with stress levels. This finding motivated a more in-depth analysis of DBP in response to stress across different age groups.\nThis section examines the variations in DBP across different stress levels, comparing young and old individuals. By analyzing these patterns, we aim to determine whether stress contributes differently to blood pressure fluctuations across age groups, which could have implications for heart attack risk.\n\n\n\n\n\n\nWhy Diastolic BP is important\n\n\n\nSystolic blood pressure reflects the pressure in the arteries when the heart beats, while diastolic blood pressure reflects the pressure between beats when the heart is at rest. Diastolic pressure is often used in clinical settings to gauge the health of the blood vessels and heart’s ability to relax. Given the context of this study, which seeks to explore the impact of stress on heart function, diastolic blood pressure provides a more relevant and sensitive measure of how stress affects the body’s ability to regulate blood flow.\n\n\nWe will first use ggscatterstats() to examine whether there is a significant correlation between DBP and stress levels. Then, we will visualize the distribution of DBP across different stress levels using a combination of stat_halfeye() and geom_boxplot() from the ggplot2 package, providing a detailed view of the data distribution and variability.\n\nCorrelation Analysis - DBP vs StressThe Plot: Distribution of Diastolic BPThe Code\n\n\n\nggscatterstats(\n  data = yesheartattack,\n  x = Stress_Levels,\n  y = Diastolic_BP,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(heartattack_filtered, aes(x = Stress, y = Diastolic_BP, fill = AgeCat)) +\n  stat_halfeye(adjust = 0.5, \n               justification = -0.2, \n               .width = 0, \n               point_colour = NA, \n               alpha = 0.4) +  # Density plot\n  geom_boxplot(width = 0.2, \n               outlier.shape = 16,  \n               outlier.color = \"black\", \n               outlier.size = 1.5, \n               alpha = 0.7) +  \n  stat_summary(fun = median, geom = \"text\",\n               aes(label = paste0(\"Median = \", round(..y.., 1))),\n               position = position_dodge(width = 0.8),\n               vjust = 0.3, size = 3, color = \"black\") +  # Add median text\n  coord_flip() +  # Flip for better readability\n  scale_fill_manual(values = c(\"Young\" = \"#63b2e3\", \"Old\" = \"#f1b6b1\")) + \n  scale_x_discrete(expand = expansion(mult = c(0.2, 0.8))) +\n  labs(title = \"Diastolic BP Across Stress Levels\",\n       x = \"Stress Levels\",\n       y = \"Diastolic Blood Pressure (mmHg)\",\n       fill = \"Age Category\") +\n  theme_economist() + \n  theme(legend.position = \"top\",\n        legend.text=element_text(size=8),\n        legend.title=element_blank(),\n        axis.title.y = element_blank())\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nThe analysis reveals a significant correlation between stress and diastolic blood pressure (DBP), with a p-value of 0.02 indicating that stress levels do indeed have an effect on DBP. The correlation coefficient (R) of -0.04 suggests a very weak negative relationship between stress and DBP, implying that, on the whole, higher stress levels are slightly associated with lower diastolic blood pressure. However, looking at the 95% confidence interval for the correlation, which ranges from -0.08 to -0.008, we can conclude that while the relationship between stress and DBP is statistically significant, its strength is not substantial.\nThe spread (IQR) of diastolic BP is wider for young individuals across all stress levels, meaning their BP varies more compared to older individuals. The density plots show that the diastolic BP distribution is slightly more concentrated for older individuals, suggesting more consistency in their BP readings.\nFor young individuals, the inverse relationship between stress and diastolic blood pressure is intriguing. Specifically, those experiencing higher levels of stress have lower median diastolic blood pressure. This could potentially be related to lifestyle factors common among younger populations, such as increased physical activity or lower levels of chronic conditions, which might help mitigate the expected increases in blood pressure with stress.\nFor older individuals, there is an direct relationship between stress and diastolic BP:\n\nOlder individuals with low stress have the lowest median BP (79.5 mmHg).\nThose with high stress have a higher median BP (80.4 mmHg).\nThis could suggest that older individuals under high stress might have increased risk of heart attack.\n\n\n\n\n\n\n5.3.4 Does Gender and Regions Matter?\nExploring the impact of gender and region (urban vs. rural) on the occurrence of heart attacks in relation to varying stress levels can reveal important insights into cardiovascular risk disparities. By examining how gender and region interact with different stress levels, we aim to identify significant patterns that may highlight increased vulnerability to heart attacks.\nWe will use a stat_halfeye() and geom_boxplot() from ggplot2 to visualize gender differences, as well as a boxplot to compare differences between individuals with and without heart attacks. Similarly, we will apply the stat_halfeye() and geom_boxplot() to examine regional differences (urban vs. rural). Lastly, we will include an interaction term between gender and region (e.g., Female.Urban and Male.Urban) to visualize the proportions of heart attack cases within these groups, helping us identify which demographic groups may be more vulnerable.\n\nGenderRegion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nStress levels increase slightly with age for both genders, with older men experiencing higher overall stress than women. Overall, male heart attack patients tend to have slightly higher stress levels, whereas female heart attack patients experience lower stress compared to their non-heart attack counterparts.\nUrban individuals report slightly higher stress than rural individuals, but rural males have the highest proportion of heart attack cases (52.3%). Despite higher stress in urban areas, heart attack rates remain lower.\n\n\n\n\n\n5.3.5 Diabetes History in Heart Attack Patients\nDiabetes is a significant risk factor for cardiovascular disease, with individuals suffering from diabetes often exhibiting higher rates of heart disease and stroke. The relationship between diabetes and heart health is complex, as diabetes can accelerate the process of fatty plaques buildup in the arteries, which increases the likelihood of heart attacks and other cardiovascular events (Mattheus et al., 2013).\nUnderstanding the influence of a history of diabetes on cardiovascular health is crucial for identifying high-risk populations. Specifically, individuals with a history of diabetes are more likely to experience complications related to blood pressure and cholesterol levels, both of which are critical indicators of heart health.\nIn this section, we will visualize the distribution of stress levels between individuals with and without a diabetes history. Using geom_boxplot() from the ggplot2 package, we will plot the stress levels, grouped by diabetes history and age category. This will help us identify any significant differences in stress levels between the groups, allowing for a clearer understanding of how diabetes history and age may influence stress.\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Calculate proportions of age categories within Diabetes History\nheartattack_diabetes&lt;- yesheartattack %&gt;% \n  group_by(Diabetes_History, AgeCat) %&gt;%\n  summarise(Count = n(), .groups = \"drop\") %&gt;%\n  group_by(Diabetes_History) %&gt;%\n  mutate(Proportion = (Count / sum(Count)) * 100) \n\n# Diabetes Age Group Barchart\ndiabetesbar &lt;- ggplot(heartattack_diabetes, aes(x = Diabetes_History, y = Proportion, fill = factor(AgeCat))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) + \n  geom_text(aes(label = sprintf(\"%.1f%%\", Proportion)), \n            position = position_dodge(width = 0.8), vjust = 0.2,hjust=1.2, size = 3) +  \n  labs(\n    title = \"Diabetes History by Age Group and Stress Level\",\n    x = \"Diabetes History\",\n    y = \"Proportion (%)\",\n    fill = \"Age Category\"\n  ) +\n  scale_fill_manual(values = c(\"Young\" = \"#ffde59\", \"Middle-Aged\" = \"#e79251\", \"Old\" = \"#9cc567\")) +\n  theme_minimal()+\n  theme(axis.title.x = element_blank())+\n  coord_flip()\n\n\n# Calculate the percentiles (25th, 50th, and 75th) for Stress Levels grouped by Diabetes History and AgeCat\nage_dia_stress_data &lt;- yesheartattack %&gt;%\n  group_by(Diabetes_History, AgeCat) %&gt;%\n  summarise(\n    median_stress = median(Stress_Levels),\n    q25_stress = quantile(Stress_Levels, 0.25),\n    q75_stress = quantile(Stress_Levels, 0.75),\n    .groups = \"drop\"\n  )\n\n# Boxplot for Age-Dia-Stress\nage_dia_stress &lt;- ggplot(yesheartattack, aes(x = Diabetes_History, y = Stress_Levels, fill = Diabetes_History)) +\n  geom_boxplot() +\n  facet_wrap(~ AgeCat) +\n  labs(\n       x = \"Diabetes History\",\n       y = \"Stress Levels\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title= element_blank()) +\n  scale_fill_manual(values = c(\"Yes\" = \"#83bace\", \"No\" = \"#e78090\")) +\n  geom_text(data = age_dia_stress_data, aes(x = Diabetes_History, y = median_stress, label = paste(\"Median:\", round(median_stress, 2))),\n            position = position_nudge(y = 0.5), size = 3, color = \"black\") +\n  geom_text(data = age_dia_stress_data, aes(x = Diabetes_History, y = q25_stress, label = paste(\"25th:\", round(q25_stress, 2))),\n            position = position_nudge(y = -0.5), size = 3, color = \"black\") +\n  geom_text(data = age_dia_stress_data, aes(x = Diabetes_History, y = q75_stress, label = paste(\"75th:\", round(q75_stress, 2))),\n            position = position_nudge(y = 0.5), size = 3, color = \"black\")\n\n\ndiabetesbar/age_dia_stress +\n  plot_layout(widths = c(1,2),heights = c(1,2))\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nThe young age category represents the highest proportion among diabetic heart attack patients, accounting for 39.7% of the total. In contrast, the old age category has the lowest proportion. This trend suggests that younger individuals with diabetes may be more susceptible to heart attacks, possibly due to factors such as early onset of diabetes or other underlying risk factors.\nFor patients with no diabetes history, the young age category still has the highest proportion, but it is lower compared to the diabetic heart attack patients. This could be explained by the overall higher proportion of younger individuals in heart attack patients in general.\nInterestingly, the middle-aged and old age categories show a higher proportion in non-diabetic heart attack patients compared to diabetic heart attack patients.\nFor old diabetic patients, stress levels appear to be significantly higher compared to other groups. However, diabetes history seems to have a notable impact only in the young age category. Specifically, young diabetic patients show higher stress levels than their non-diabetic counterparts. In contrast, for both the middle-aged and old groups, this relationship is reversed: older diabetic patients tend to have lower stress levels than their non-diabetic counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "4.1 Installing and Launching R Packages",
    "text": "4.1 Installing and Launching R Packages\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "4.3 Plotting Static Parallel Coordinates Plot",
    "text": "4.3 Plotting Static Parallel Coordinates Plot\nWe use the same data as section3.\n\n4.3.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures.\n\n\n4.3.2 Plotting a parallel coordinates with boxplot\n\nExplanationCode\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\n\n4.3.4 Rotating x-axis text label\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\n4.3.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "4.4 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "4.4 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js.\n\n4.4.1 The basic plot\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\n4.4.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n4.4.3 Changing the colour scheme\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n4.4.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-4",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-4",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "5.1 Installing and Launching R Packages",
    "text": "5.1 Installing and Launching R Packages\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "5.2 Data Wrangling",
    "text": "5.2 Data Wrangling\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n5.2.1 Grouped summaries without the Pipe\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n5.2.2 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "5.3 Designing Treemap with treemap Package",
    "text": "5.3 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments.\n\n5.3.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\nExplanationCode\n\n\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\n\n\n\n\n\n\n\n\n5.3.2 Working with vColor and type arguments\n\nCodePoints to Note\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\n\n\n5.3.3 Colours in treemap package - The “value” type treemap\n\nCodeThings to Note\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\n\n\n5.3.4 Colours in treemap package - The “manual” type treemap\n\nCodeThings to Note\n\n\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\n\n\n\nTo overcome this:\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.3.5 Treemap Layout\n\nWorking with algorithm argument\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThe findings suggest that regions with higher median unit prices, such as the Central Region, tend to have smaller unit sales compared to the Outside Central Region, where more transactions occur at lower price points.\n\n\nUsing sortID\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThe results indicate that premium condominiums, such as River Valley, appear more prominently due to their high transacted prices, whereas projects in suburban regions like are ranked lower with relatively more transactions at affordable prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "5.4 Designing Treemap using treemapify Package",
    "text": "5.4 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify.\n\n5.4.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n5.4.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 05:Visual Multivariate Analysis",
    "section": "5.5 Designing Interactive Treemap using d3treeR",
    "text": "5.5 Designing Interactive Treemap using d3treeR\n\n5.5.1 Installing d3treeR package\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nlibrary(d3treeR)\n\n\n\n5.5.2 Designing An Interactive Treemap\n1.treemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n2.Then d3tree() is used to build an interactive treemap.\n\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\" )\n\n\n\n\n\nKey Insights from the Interactive treemap\n\nEast Region Dominance\n\nThe East Region has the highest median unit prices, especially in prime locations such as Bedok.\nThese areas have smaller transaction volumes, but the unit prices remain significantly higher than in other regions.\n\nCentral Regions\n\nThe Central Region, particularly Bukit Timah and Novena, shows a moderate number of transactions with mid-range pricing.\n\nAffordable Housing in the North and West Regions\n\nThe North Region (e.g., Woodlands, Yishun) and West Region (e.g., Jurong, Bukit Batok) tend to have the largest transaction volumes but at significantly lower prices.\nThese areas are popular among buyers looking for affordability and potential future growth due to ongoing infrastructure developments."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "SmartEDA: productive tool to organize our data to do EDA effectively\ngtsummary: summarize modelling results and create elegant table for reporting purposes\n\npacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary,ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-the-variables",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-the-variables",
    "title": "In-class_Ex05",
    "section": "3.1 Visualizing the variables",
    "text": "3.1 Visualizing the variables\n\n3.1.1 Continuous variables\nExpNumViz from the SmartEDA without target variable creates density plots and also display skewness and kurtosis at the same time.\nPage lets us control how many plots should placed side by side. 2x2 will give 4 in one page.\nnlim will exclude the numeric variable which is having less than nlim unique value.\n\nWithout Target VariableWith Target Variable\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target= NULL,\n            nlim = 10,\n            Page = c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target= \"Price\",\n            nlim = 10,\n            Page = c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Categorical variables\nExpCatViz from the SmartEDA willl display all the categorical variables in barcharts. Change the figure width and height to visualize better in HTML (default is 8).\n\ncar_resale %&gt;%\n  ExpCatViz(target= NULL,\n            col=\"sky blue\",\n            clim = 10,\n            margin=2,\n            Page = c(4,4),\n            sample=16)\n\n$`0`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#checking-for-multicollinearity",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#checking-for-multicollinearity",
    "title": "In-class_Ex05",
    "section": "4.1 Checking for Multicollinearity",
    "text": "4.1 Checking for Multicollinearity\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nPlot() is a see package from easystats. It creates plots using ggplot function by consuming objects.\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\nBecause there is high VIF between Age and Manufacturing Year, we will remove one from this pair and rebuild the new model. Then we check for normality assumption."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#final-model-and-checks",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#final-model-and-checks",
    "title": "In-class_Ex05",
    "section": "4.2 Final Model and Checks",
    "text": "4.2 Final Model and Checks\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period,data=car_resale)\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\ncheck_heteroscedasticity(model1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\ncheck_model() is using ggplot and patchwork to group all together. It combines all normality, linearity and homogeneity.\n\n\n\n\n\n\nTo check:\n\n\n\n\nFor linearity test, it should be a linear line to conform. Possible cause for not conforming: there is an outlier or maybe heteroscedasticity\nValues should be all around the horizontal line to conform to normality of residuals.\nInfluential Observation: Shows the 95% confidence interval, Red is the significant outlier (consider to remove and rerun model), Green ones are out of the CI.\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10249.4   -768.6    -15.4    738.5   6356.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.186e+03  9.722e+02  -2.248   0.0247 *  \nAge_08_04        -1.195e+02  2.760e+00 -43.292   &lt;2e-16 ***\nKM               -2.406e-02  1.201e-03 -20.042   &lt;2e-16 ***\nWeight            1.972e+01  8.379e-01  23.533   &lt;2e-16 ***\nGuarantee_Period  2.682e+01  1.261e+01   2.126   0.0336 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1413 on 1431 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8482 \nF-statistic:  2005 on 4 and 1431 DF,  p-value: &lt; 2.2e-16\n\n\nInstead of summary (), we can use tbl_regression() from gt_summary package reorganizes the results in a clear report.\n\ntbl_regression(model1,\n               intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\n1\np-value\n\n\n\n\n(Intercept)\n-2,186\n-4,093, -278\n0.025\n\n\nAge_08_04\n-119\n-125, -114\n&lt;0.001\n\n\nKM\n-0.02\n-0.03, -0.02\n&lt;0.001\n\n\nWeight\n20\n18, 21\n&lt;0.001\n\n\nGuarantee_Period\n27\n2.1, 52\n0.034\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\n\n\nTo further customize our result report, we will use the following code chunk to add in Rsquare, AIC, p value and sigma for the whole model.\n\ntbl_regression(model1,\n               intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    label = list (sigma ~ \"\\U03C3\"),\n    include = c (r.squared, adj.r.squared,\n                 AIC, statistic,\n                 p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n\n      Beta\n\n      95% CI\n1\n      p-value\n\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R² = 0.849; Adjusted R² = 0.848; AIC = 24,915; Statistic = 2,005; p-value = &lt;0.001; σ = 1,413\n\n    \n  \n  \n    \n      1 CI = Confidence Interval\n\n    \n  \n\n\n\n\n\np_model1&lt;-parameters(model1)\np_model1\n\nParameter        | Coefficient |       SE |              95% CI | t(1431) |      p\n----------------------------------------------------------------------------------\n(Intercept)      |    -2185.52 |   972.19 | [-4092.59, -278.45] |   -2.25 | 0.025 \nAge 08 04        |     -119.49 |     2.76 | [ -124.91, -114.08] |  -43.29 | &lt; .001\nKM               |       -0.02 | 1.20e-03 | [   -0.03,   -0.02] |  -20.04 | &lt; .001\nWeight           |       19.72 |     0.84 | [   18.08,   21.36] |   23.53 | &lt; .001\nGuarantee Period |       26.82 |    12.61 | [    2.08,   51.56] |    2.13 | 0.034 \n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\nggcoefstats(model1,\n            output = \"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#recoding-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#recoding-variables",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "7.1 Recoding Variables",
    "text": "7.1 Recoding Variables\n\n7.1.1 Recoding Continuous Variables\nTo ensure that all continuous variables are on comparable scales and to avoid any one variable disproportionately influencing the model, we will scale these continuous variables between 0 and 1. This is especially important when the variables are on vastly different scales (for example, BMI vs. Heart Rate), as it ensures that the model treats them equally, improving the interpretability and stability of the regression results.\nBy scaling variables, each predictor has the same weight in the logistic regression model, preventing the model from being biased towards variables with larger numerical ranges. We will use the following code to create a new dataframe for the logistic regression with the name, heartattack_lr.\n\nheartattack_lr &lt;- heartattack %&gt;%\n  mutate(\n    Cholesterol_Level = rescale(Cholesterol_Level, to = c(0, 1)),\n    BMI = rescale(BMI, to = c(0, 1)),\n    Heart_Rate = rescale(Heart_Rate, to = c(0, 1)),\n    Systolic_BP = rescale(Systolic_BP, to = c(0, 1)),\n    Diastolic_BP = rescale(Diastolic_BP, to = c(0, 1))\n  )\n\n\n\n7.1.2 Recoding Categorical Variables\nLogistic regression requires numerical input, so categorical variables—such as gender, region, and family history—must be converted into numerical values.\nCategorical variables are either binary or multilevel for our dataset. For binary variables (such as Gender, Smoking History, and Hypertension History), we will recode the categories into two values: 0 and 1, where 0 typically represents the absence of the condition and 1 represents the presence.\nFor variables with more than two levels (such as Physical Activity, Region, and Diet Quality), we will assign each level a unique integer. These variables will be recoded into 0, 1, or 2 values, where each number represents a distinct category, allowing the logistic regression model to treat the categories appropriately without losing the ordinal information.\nThe following table shows how the categorical variables will be recoded.\n\n\n\n\n\n\n\nBinary (Recoded to 0 and 1)\n3 Levels (Recoded to 0,1,2)\n\n\n\n\nGender: Female/Male\nPhysical_Activity: Low/Moderate/High\n\n\nRegion: Urban/Rural\nDiet_Quality: Poor/Average/Good\n\n\nSmoking_History: Yes/No\nAlcohol_Consumption: Low/Moderate/High\n\n\nDiabetes_History: Yes/No\nAgeCat: Young/Middle-Aged/Old\n\n\nHypertension_History: Yes/No\n\n\n\nFamily_History: Yes/No\n\n\n\n\n\nheartattack_lr &lt;- heartattack_lr %&gt;%\n  mutate(\n    # Binary variables: 0 = No, 1 = Yes\n    Gender = ifelse(Gender == \"Female\", 0, 1),  \n    Region = ifelse(Region == \"Urban\", 0, 1),  \n    Smoking_History = ifelse(Smoking_History == \"No\", 0, 1),  \n    Diabetes_History = ifelse(Diabetes_History == \"No\", 0, 1),  \n    Hypertension_History = ifelse(Hypertension_History == \"No\", 0, 1), \n    Family_History = ifelse(Family_History == \"No\", 0, 1),  \n    \n    # Three-level variables: 0 = Low/Poor/Young, 1 = Moderate/Average/Middle-Aged, 2 = High/Good/Old\n    Physical_Activity = recode(Physical_Activity, \"Low\" = 0, \"Moderate\" = 1, \"High\" = 2),\n    Diet_Quality = recode(Diet_Quality, \"Poor\" = 0, \"Average\" = 1, \"Good\" = 2),\n    Alcohol_Consumption = recode(Alcohol_Consumption, \"Low\" = 0, \"Moderate\" = 1, \"High\" = 2),\n    AgeCat = recode(AgeCat, \"Young\" = 0, \"Middle-Aged\" = 1, \"Old\" = 2),\n    Stress = recode(Stress, \"Low\" = 0, \"Medium\" = 1, \"High\" = 2)\n  )\n\n\n\n7.1.3 Recoding Dependent Variable\nWe also recode the dependent variable for logistic regression.\nThe original dependent variable, Heart_Attack_Occurrence has responses such as “Yes” and “No.” For logistic regression, we need to convert this categorical variable into numeric values. We will recode the variable as follows:\n\n1: Indicates the occurrence of a heart attack (Yes)\n0: Indicates no occurrence of a heart attack (No)\n\n\nheartattack_lr &lt;- heartattack_lr %&gt;%\n  mutate(Heart_Attack_Recode = ifelse(Heart_Attack_Occurrence == \"Yes\", 1, 0))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-models",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-models",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "7.2 The Models",
    "text": "7.2 The Models\nWe are now ready for building logistic regression models specifically for the young category individuals. The goal is to evaluate how well various predictor variables influence the likelihood of a heart attack occurrence among younger individuals (defined in the dataset as those categorized as “Young”).\nTo enhance our understanding, we will also build a logistic regression model for the old category for comparison. By comparing these models, we can examine whether different age groups exhibit distinct risk factors for heart attack occurrences. This comparison can provide valuable insights into whether certain predictors are more relevant for younger individuals or if they affect all age groups similarly.\n\n7.2.1 Logistic Regression Model for Young Category\nWe first build a base logistic regression model as the initial model that includes all predictor variables without any further optimization.\nThen we refine the model using the forward stepwise regression method to systematically add predictors one by one, based on their statistical significance. This approach allows us to identify the most relevant variables while removing those that do not contribute significantly to the model’s predictive power.\n\nheartattack_young &lt;- heartattack_lr %&gt;%\n  filter(AgeCat == 0)\n\n\nheartattack_lr_young &lt;- glm(Heart_Attack_Recode ~ \n                              Gender + \n                              Region + \n                              Smoking_History + \n                              Diabetes_History + \n                              Hypertension_History + \n                              Family_History + \n                              Physical_Activity + \n                              Diet_Quality + \n                              Alcohol_Consumption + \n                              Cholesterol_Level+\n                              Stress+\n                              BMI+\n                              Systolic_BP+\n                              Diastolic_BP+\n                              Heart_Rate, \n                            data = heartattack_young, \n                            family = binomial())\n\nheartattack_lr_young_step &lt;- step(heartattack_lr_young, \n                                       direction = \"forward\", \n                                       trace = FALSE)\nsummary(heartattack_lr_young_step)\n\n\nCall:\nglm(formula = Heart_Attack_Recode ~ Gender + Region + Smoking_History + \n    Diabetes_History + Hypertension_History + Family_History + \n    Physical_Activity + Diet_Quality + Alcohol_Consumption + \n    Cholesterol_Level + Stress + BMI + Systolic_BP + Diastolic_BP + \n    Heart_Rate, family = binomial(), data = heartattack_young)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -2.113367   0.331425  -6.377 1.81e-10 ***\nGender                0.035216   0.069245   0.509   0.6111    \nRegion                0.019063   0.074879   0.255   0.7990    \nSmoking_History      -0.009142   0.075747  -0.121   0.9039    \nDiabetes_History      0.205928   0.081794   2.518   0.0118 *  \nHypertension_History  0.122994   0.078220   1.572   0.1159    \nFamily_History       -0.032549   0.076038  -0.428   0.6686    \nPhysical_Activity    -0.039023   0.044523  -0.876   0.3808    \nDiet_Quality          0.063859   0.046383   1.377   0.1686    \nAlcohol_Consumption  -0.031345   0.046821  -0.669   0.5032    \nCholesterol_Level    -0.116074   0.298043  -0.389   0.6969    \nStress               -0.109263   0.051843  -2.108   0.0351 *  \nBMI                  -0.090155   0.279490  -0.323   0.7470    \nSystolic_BP          -0.100789   0.282966  -0.356   0.7217    \nDiastolic_BP          0.100331   0.268195   0.374   0.7083    \nHeart_Rate           -0.067279   0.272703  -0.247   0.8051    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6094.1  on 9593  degrees of freedom\nResidual deviance: 6076.9  on 9578  degrees of freedom\n  (1123 observations deleted due to missingness)\nAIC: 6108.9\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nDiabetes history is the most significant predictor in the model for younger individuals, indicating that having a history of diabetes increases the risk of a heart attack.\nStress levels is also significant for young individuals. However, it is a slight negative relationship with heart attack occurrence, meaning that higher stress levels may be associated with a lower likelihood of experiencing a heart attack in this age group, which could be due to the complexity of stress as a factor—possibly indicating that individuals with higher stress may be more likely to engage in behaviors or seek treatments that reduce heart attack risk.\nAll other predictors are insignificant.\n\n\n\n\n\n7.2.2 Logistic Regression Model for Old Category\nAgain, we do the same for the old category.\n\nheartattack_old &lt;- heartattack_lr %&gt;%\n  filter(AgeCat == 2)\n\n\nheartattack_lr_old &lt;- glm(Heart_Attack_Recode ~ \n                              Gender + \n                              Region + \n                              Smoking_History + \n                              Diabetes_History + \n                              Hypertension_History + \n                              Family_History + \n                              Physical_Activity + \n                              Diet_Quality + \n                              Alcohol_Consumption + \n                              Cholesterol_Level+\n                              Stress+\n                              BMI+\n                              Systolic_BP+\n                              Diastolic_BP+\n                              Heart_Rate, \n                            data = heartattack_old, \n                            family = binomial())\n\nheartattack_lr_old_step&lt;- step(heartattack_lr_old, \n                                               direction = \"forward\", \n                                               trace = FALSE)\nsummary(heartattack_lr_old_step)\n\n\nCall:\nglm(formula = Heart_Attack_Recode ~ Gender + Region + Smoking_History + \n    Diabetes_History + Hypertension_History + Family_History + \n    Physical_Activity + Diet_Quality + Alcohol_Consumption + \n    Cholesterol_Level + Stress + BMI + Systolic_BP + Diastolic_BP + \n    Heart_Rate, family = binomial(), data = heartattack_old)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -2.291243   0.342506  -6.690 2.24e-11 ***\nGender               -0.015602   0.071804  -0.217    0.828    \nRegion               -0.114997   0.080864  -1.422    0.155    \nSmoking_History       0.059233   0.078156   0.758    0.449    \nDiabetes_History     -0.006976   0.089854  -0.078    0.938    \nHypertension_History -0.078347   0.085511  -0.916    0.360    \nFamily_History       -0.036489   0.078968  -0.462    0.644    \nPhysical_Activity    -0.041640   0.046326  -0.899    0.369    \nDiet_Quality         -0.024867   0.048082  -0.517    0.605    \nAlcohol_Consumption  -0.057183   0.049439  -1.157    0.247    \nCholesterol_Level     0.452076   0.306888   1.473    0.141    \nStress                0.016078   0.053551   0.300    0.764    \nBMI                  -0.083856   0.292348  -0.287    0.774    \nSystolic_BP          -0.125447   0.294332  -0.426    0.670    \nDiastolic_BP         -0.016944   0.277933  -0.061    0.951    \nHeart_Rate            0.274086   0.281972   0.972    0.331    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5635.4  on 8746  degrees of freedom\nResidual deviance: 5625.7  on 8731  degrees of freedom\n  (967 observations deleted due to missingness)\nAIC: 5657.7\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThe logistic regression model for the old category indicates that only cholesterol level might have some marginal relevance,with a p value of 0.141, but overall, many of the variables do not show a significant impact."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparison-of-models",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#comparison-of-models",
    "title": "Take-home Exercise 01: Visualizing and Uncovering Trends on Heart Attacks in Japan",
    "section": "7.3 Comparison of Models",
    "text": "7.3 Comparison of Models\n\nYoungOld\n\n\n\ntbl_regression(heartattack_lr_young_step,\n               intercept = TRUE,\n               estimate_fun = purrr::partial(style_sigfig, digits = 4)) %&gt;%\n  add_glance_source_note(\n    include = c(AIC, BIC, deviance, df.residual))\n\n\n\n\n  \n    \n      Characteristic\n\n      log(OR)\n1\n      95% CI\n1\n      p-value\n\n    \n  \n  \n    (Intercept)\n-2.113\n-2.765, -1.466\n&lt;0.001\n    Gender\n0.0352\n-0.1005, 0.1710\n0.6\n    Region\n0.0191\n-0.1288, 0.1648\n0.8\n    Smoking_History\n-0.0091\n-0.1589, 0.1382\n&gt;0.9\n    Diabetes_History\n0.2059\n0.0438, 0.3646\n0.012\n    Hypertension_History\n0.1230\n-0.0318, 0.2749\n0.12\n    Family_History\n-0.0325\n-0.1829, 0.1153\n0.7\n    Physical_Activity\n-0.0390\n-0.1263, 0.0482\n0.4\n    Diet_Quality\n0.0639\n-0.0267, 0.1551\n0.2\n    Alcohol_Consumption\n-0.0313\n-0.1233, 0.0603\n0.5\n    Cholesterol_Level\n-0.1161\n-0.7004, 0.4681\n0.7\n    Stress\n-0.1093\n-0.2112, -0.0079\n0.035\n    BMI\n-0.0902\n-0.6381, 0.4576\n0.7\n    Systolic_BP\n-0.1008\n-0.6553, 0.4540\n0.7\n    Diastolic_BP\n0.1003\n-0.4254, 0.6260\n0.7\n    Heart_Rate\n-0.0673\n-0.6017, 0.4674\n0.8\n  \n  \n    \n      AIC = 6,109; BIC = 6,224; Deviance = 6,077; Residual df = 9,578\n\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n\n    \n  \n\n\n\n\n\n\n\ntbl_regression(heartattack_lr_old_step,\n               intercept = TRUE,\n               estimate_fun = purrr::partial(style_sigfig, digits = 4)) %&gt;%\n  add_glance_source_note(\n    include = c(AIC, BIC, deviance, df.residual))\n\n\n\n\n  \n    \n      Characteristic\n\n      log(OR)\n1\n      95% CI\n1\n      p-value\n\n    \n  \n  \n    (Intercept)\n-2.291\n-2.965, -1.622\n&lt;0.001\n    Gender\n-0.0156\n-0.1564, 0.1252\n0.8\n    Region\n-0.1150\n-0.2751, 0.0420\n0.2\n    Smoking_History\n0.0592\n-0.0952, 0.2113\n0.4\n    Diabetes_History\n-0.0070\n-0.1857, 0.1667\n&gt;0.9\n    Hypertension_History\n-0.0783\n-0.2481, 0.0873\n0.4\n    Family_History\n-0.0365\n-0.1927, 0.1170\n0.6\n    Physical_Activity\n-0.0416\n-0.1325, 0.0491\n0.4\n    Diet_Quality\n-0.0249\n-0.1189, 0.0697\n0.6\n    Alcohol_Consumption\n-0.0572\n-0.1543, 0.0395\n0.2\n    Cholesterol_Level\n0.4521\n-0.1493, 1.054\n0.14\n    Stress\n0.0161\n-0.0891, 0.1209\n0.8\n    BMI\n-0.0839\n-0.6571, 0.4890\n0.8\n    Systolic_BP\n-0.1254\n-0.7022, 0.4516\n0.7\n    Diastolic_BP\n-0.0169\n-0.5616, 0.5280\n&gt;0.9\n    Heart_Rate\n0.2741\n-0.2785, 0.8270\n0.3\n  \n  \n    \n      AIC = 5,658; BIC = 5,771; Deviance = 5,626; Residual df = 8,731\n\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\n1. Significance of Predictors:\n\nYoung Category: Significant predictors such as Diabetes History (positive relationship with heart attack risk) and Stress Levels (negative relationship with heart attack risk) suggest that lifestyle and health conditions like diabetes, alongside stress, play an important role in the likelihood of heart attacks in the young.\nOld Category: There are no significant predictors in the old category.The lack of significant results may be due to the age group having a more homogeneous risk factor profile, with factors such as age playing a dominant role in heart attack occurrence.\n\n\n\n2. Model Fit:\n\nYoung Category: The model for the young category has a residual deviance of 6077 and an AIC of 6109.6, indicating that the model fits the data moderately well. The significance of a few variables suggests that the model explains some variation in heart attack occurrence.\nOld Category: The residual deviance for the old category is 5625, and the AIC is 5658, which also indicates a reasonable model fit, although no variables were found to be statistically significant."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "",
    "text": "Since Donald Trump assumed the U.S. presidency on January 20, 2025, global trade has been a focal point of economic discussions. Singapore, as a highly open economy, is deeply affected by shifts in international trade policies and global economic trends. Understanding how Singapore’s merchandise trade has evolved since 2015 provides valuable insights into the country’s trade resilience, shifting market dependencies, and economic positioning.\nThis study focuses on leveraging visual analytics and time-series techniques to explore Singapore’s international trade data. By analyzing historical trade patterns, identifying trends, and applying forecasting methods, this study aims to generate actionable insights into Singapore’s trade performance over the past decade.\n\n\n\nThe primary objectives of this study are:\n\nData Visualization Critique & Redesign: Select three existing data visualizations from the dataset’s webpage, critically evaluate their effectiveness, identify strengths and weaknesses, and propose and create improved visual representations.\nTime-Series Analysis: Apply appropriate time-series techniques to analyze trends in Singapore’s merchandise trade. Derive meaningful conclusions from the visualizations and time-series analysis, explaining key trade trends, shifts in trade regions, and potential implications for Singapore’s economy."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#background",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#background",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "",
    "text": "Since Donald Trump assumed the U.S. presidency on January 20, 2025, global trade has been a focal point of economic discussions. Singapore, as a highly open economy, is deeply affected by shifts in international trade policies and global economic trends. Understanding how Singapore’s merchandise trade has evolved since 2015 provides valuable insights into the country’s trade resilience, shifting market dependencies, and economic positioning.\nThis study focuses on leveraging visual analytics and time-series techniques to explore Singapore’s international trade data. By analyzing historical trade patterns, identifying trends, and applying forecasting methods, this study aims to generate actionable insights into Singapore’s trade performance over the past decade."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "",
    "text": "The primary objectives of this study are:\n\nData Visualization Critique & Redesign: Select three existing data visualizations from the dataset’s webpage, critically evaluate their effectiveness, identify strengths and weaknesses, and propose and create improved visual representations.\nTime-Series Analysis: Apply appropriate time-series techniques to analyze trends in Singapore’s merchandise trade. Derive meaningful conclusions from the visualizations and time-series analysis, explaining key trade trends, shifts in trade regions, and potential implications for Singapore’s economy."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data-and-removing-irrelevant-rows",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data-and-removing-irrelevant-rows",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "4.1 Importing the Data and Removing Irrelevant Rows",
    "text": "4.1 Importing the Data and Removing Irrelevant Rows\nThe code chunk below imports MerchanciseTrade.xlsx as three dataframes - imports, exports and reexports- into R environment by using read_xlsx( ) from readxl package. “sheet =” tells which worksheet to read as our dataset contains multiple worksheets.\nThe Excel sheets also contain irrelevant rows, including data descriptions and footnotes, which need to be removed as we import. Specifically:\n\nRows 1 to 9 contain metadata and are not part of the actual dataset.\nRow 10 contains column headers and should be set as variable names.\nRows 171 to 191 contain footnotes and other non-relevant information that should be excluded.\n\nTo ensure a clean dataset, we will remove these rows and set Row 10 as the header.\n\nImportsExportsRe-Exports\n\n\n\nimports &lt;- read_xlsx(\"data/MerchandiseTrade.xlsx\", sheet = \"T1\",skip = 9) %&gt;%\n  slice(1:161)\ncolnames(imports) &lt;- as.character(imports[1, ])  # Assign first row as column names\nimports &lt;- imports[-1, ]\n\n\n\n\nexports &lt;- read_xlsx(\"data/MerchandiseTrade.xlsx\", sheet = \"T2\",skip = 9) %&gt;%\n  slice(1:161)\ncolnames(exports) &lt;- as.character(exports[1, ])  # Assign first row as column names\nexports &lt;- exports[-1, ]\n\n\n\n\nreexports &lt;- read_xlsx(\"data/MerchandiseTrade.xlsx\", sheet = \"T3\",skip = 9) %&gt;%\n  slice(1:161)\ncolnames(reexports) &lt;- as.character(reexports[1, ])  # Assign first row as column names\nreexports &lt;- reexports[-1, ]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-for-missing-values",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-for-missing-values",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "4.2 Checking for Missing values",
    "text": "4.2 Checking for Missing values\nThe ExpData from SmartEDA package provides a quick overview of data types and missing values.\n\nImportsExportsReexports\n\n\n\nimports %&gt;%\n  ExpData(type=1)\n\n                                          Descriptions      Value\n1                                   Sample size (nrow)        160\n2                              No. of variables (ncol)        266\n3                    No. of numeric/interger variables          0\n4                              No. of factor variables          0\n5                                No. of text variables        266\n6                             No. of logical variables          0\n7                          No. of identifier variables          1\n8                                No. of date variables          0\n9             No. of zero variance variables (uniform)          0\n10               %. of variables having complete cases 100% (266)\n11   %. of variables having &gt;0% and &lt;50% missing cases     0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases     0% (0)\n13          %. of variables having &gt;=90% missing cases     0% (0)\n\n\n\n\n\nexports %&gt;%\n  ExpData(type=1)\n\n                                          Descriptions      Value\n1                                   Sample size (nrow)        160\n2                              No. of variables (ncol)        266\n3                    No. of numeric/interger variables          0\n4                              No. of factor variables          0\n5                                No. of text variables        266\n6                             No. of logical variables          0\n7                          No. of identifier variables          1\n8                                No. of date variables          0\n9             No. of zero variance variables (uniform)          0\n10               %. of variables having complete cases 100% (266)\n11   %. of variables having &gt;0% and &lt;50% missing cases     0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases     0% (0)\n13          %. of variables having &gt;=90% missing cases     0% (0)\n\n\n\n\n\nreexports %&gt;%\n  ExpData(type=1)\n\n                                          Descriptions      Value\n1                                   Sample size (nrow)        160\n2                              No. of variables (ncol)        266\n3                    No. of numeric/interger variables          0\n4                              No. of factor variables          0\n5                                No. of text variables        266\n6                             No. of logical variables          0\n7                          No. of identifier variables          1\n8                                No. of date variables          0\n9             No. of zero variance variables (uniform)          0\n10               %. of variables having complete cases 100% (266)\n11   %. of variables having &gt;0% and &lt;50% missing cases     0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases     0% (0)\n13          %. of variables having &gt;=90% missing cases     0% (0)\n\n\n\n\n\nBased on the results, all three data frames contain 100% complete cases, indicating the absence of missing values."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-columns-and-converting-data-type",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-columns-and-converting-data-type",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "4.3 Renaming Columns and Converting Data Type",
    "text": "4.3 Renaming Columns and Converting Data Type\nInitially, all variables in the dataset are stored as character data types. However, since all columns (except for Data Series) represent trade values in millions of SGD, they should be converted to numeric format. Additionally, we will rename the Data Series column to Markets for better readability.\nThe column names represent dates in the “YYYY MMM” format (e.g., \"2025 Jan\", \"2024 Dec\"). To analyze the data effectively as a time series, we will need to :\n\nReshape the dataset from wide to long format – Instead of having separate columns for each month, we will structure the data so that each row represents a month and its corresponding trade value. A long format is particularly beneficial when working with ggplot2 because it simplifies faceting and makes data manipulation and visualization more flexible.\nConvert the date column to a proper date format (YYYY-MM) – This ensures consistency and compatibility with time series analysis and visualization.\n\n\nImportsExportsReexports\n\n\n\nimports &lt;- imports %&gt;%\n  rename(Markets = `Data Series`) %&gt;% \n  mutate(across(-Markets, as.numeric)) %&gt;%\n  pivot_longer(cols = -Markets, names_to = \"Date\", values_to = \"Trade_Value\")%&gt;%\n  mutate(Date = parse_date_time(Date, orders = \"ym\"))%&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  arrange(Date)\n\nhead(imports)\n\n# A tibble: 6 × 3\n  Markets             Date       Trade_Value\n  &lt;chr&gt;               &lt;date&gt;           &lt;dbl&gt;\n1 Total All Markets   2003-01-01     18539. \n2 America             2003-01-01      2385. \n3 Antigua And Barbuda 2003-01-01         0  \n4 Argentina           2003-01-01         2.3\n5 Bahamas             2003-01-01        19.2\n6 Bermuda             2003-01-01         0  \n\n\n\n\n\nexports &lt;- exports %&gt;%\n  rename(Markets = `Data Series`) %&gt;% \n  mutate(across(-Markets, as.numeric))%&gt;%\n  pivot_longer(cols = -Markets, names_to = \"Date\", values_to = \"Trade_Value\")%&gt;%\n  mutate(Date = parse_date_time(Date, orders = \"ym\"))%&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  arrange(Date)\n\n\n\n\nreexports &lt;- reexports %&gt;%\n  rename(Markets = `Data Series`) %&gt;% \n  mutate(across(-Markets, as.numeric))%&gt;%\n  pivot_longer(cols = -Markets, names_to = \"Date\", values_to = \"Trade_Value\")%&gt;%\n  mutate(Date = parse_date_time(Date, orders = \"ym\"))%&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  arrange(Date)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#grouping-region-or-country",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#grouping-region-or-country",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "4.4 Grouping Region or Country",
    "text": "4.4 Grouping Region or Country\nThe dataset contains rows that represent regions (e.g., “Total All Market”, “America”, “Asia”, “Oceania”, “Europe”, and “Africa”) alongside rows for individual countries. To facilitate analysis, we will add a new column (RegionorCountry) to classify each row as either a region or a country.\nThis classification allows us to easily filter out the region rows from analyses focused on country-level data, such as when creating visualizations or performing modeling tasks.\nIf we choose to exclude the region rows for specific analyses, we can filter them out using the newly created column, keeping only the country data for detailed exploration.\n\nImportsExportsReexports\n\n\n\n# Adding new coulumn \nimports &lt;- imports %&gt;%\n  mutate(RegionorCountry = ifelse(Markets %in% c(\"Total All Markets\", \"America\", \"Asia\", \"Oceania\", \"Europe\", \"Africa\"), \n                                    \"Region\", \"Country\"))\n\nhead(imports)\n\n# A tibble: 6 × 4\n  Markets             Date       Trade_Value RegionorCountry\n  &lt;chr&gt;               &lt;date&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Total All Markets   2003-01-01     18539.  Region         \n2 America             2003-01-01      2385.  Region         \n3 Antigua And Barbuda 2003-01-01         0   Country        \n4 Argentina           2003-01-01         2.3 Country        \n5 Bahamas             2003-01-01        19.2 Country        \n6 Bermuda             2003-01-01         0   Country        \n\n\n\n\n\n# Adding new coulumn \nexports &lt;- exports %&gt;%\n  mutate(RegionorCountry = ifelse(Markets %in% c(\"Total All Markets\", \"America\", \"Asia\", \"Oceania\", \"Europe\", \"Africa\"), \n                                    \"Region\", \"Country\"))\n\n\n\n\n# Adding new coulumn \nreexports &lt;- reexports %&gt;%\n  mutate(RegionorCountry = ifelse(Markets %in% c(\"Total All Markets\", \"America\", \"Asia\", \"Oceania\", \"Europe\", \"Africa\"), \n                                    \"Region\", \"Country\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#combining-into-one-dataframe",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#combining-into-one-dataframe",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "4.5 Combining into One Dataframe",
    "text": "4.5 Combining into One Dataframe\nAfter all our data preparation, we can combine the three newly prepared datasets into a single unified dataframe. This step allows us to work with the data as a whole while preserving the distinction between the different trade categories. To achieve this, we use the bind_rows() function to stack the datasets and add a new column, Type, which indicates whether a row corresponds to Imports, Exports, or Re-Exports.\nThis combined dataframe will be more convenient for analysis, as it enables us to analyze trade data across different categories while keeping the data structured.\n\nimports &lt;- imports %&gt;%\n  mutate(Type = \"Import\")\n\nexports &lt;- exports %&gt;%\n  mutate(Type = \"Export\")\n\nreexports &lt;- reexports %&gt;%\n  mutate(Type = \"Re-Export\")\n\n# Combine all three datasets using bind_rows()\ntrade &lt;- bind_rows(imports, exports, reexports)\n\nhead(trade)\n\n# A tibble: 6 × 5\n  Markets             Date       Trade_Value RegionorCountry Type  \n  &lt;chr&gt;               &lt;date&gt;           &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt; \n1 Total All Markets   2003-01-01     18539.  Region          Import\n2 America             2003-01-01      2385.  Region          Import\n3 Antigua And Barbuda 2003-01-01         0   Country         Import\n4 Argentina           2003-01-01         2.3 Country         Import\n5 Bahamas             2003-01-01        19.2 Country         Import\n6 Bermuda             2003-01-01         0   Country         Import\n\n\nNow, we can proceed to keep a subset of the dataframe on country-level data by excluding the regions.\n\n# Filter only countries (exclude regions)\ncountry &lt;- trade %&gt;% filter(RegionorCountry == \"Country\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-1-barchart-of-total-merchandise-trade-2020---2024",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-1-barchart-of-total-merchandise-trade-2020---2024",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "5.1 Visualization 1: Barchart of Total Merchandise Trade, 2020 - 2024",
    "text": "5.1 Visualization 1: Barchart of Total Merchandise Trade, 2020 - 2024\n\n\n\n\n\nThe barchart presents the total merchandise trade for the years 2020 through 2024, with each year showing two bars—representing export and import values. There are bubbles beside the bars indicating the combined total trade value for each year. A textbox also notes a 6.6% increase in trade in 2024.\n\n5.1.1 Pros and Cons\nPros:\n\nThe color coding by year makes it easier to distinguish between the different years, providing clarity at a glance.\nClear trade value labels in each bar help viewers quickly identify the trade volume for both exports and imports.\n\nCons:\n\nThe textbox stating “Increased 6.6% in 2024” is not effectively supported by the barchart itself. The viewer is left wondering what exactly increased and from which point the 6.6% growth is being measured (compared to 2023 or from the beginning of 2020).\nThe description does not explicitly explain that “exports” include “re-exports,” which could lead to confusion for viewers since exports are higher than imports every year.\nThe total trade value for each year is not immediately clear, as it is displayed separately in a bubble, which might make it harder for viewers to correlate the bubble value with the corresponding bars.\n\n\n\n5.1.2 Makeover\nTo improve the visualization, several changes were made:\n\nA line chart was added alongside the bar chart to show percentage changes in trade over the years, providing context to fluctuations. This highlights trends, such as the recovery from a sharp decline in 2023 (-11.7%), emphasizing that the 6.6% increase in 2024 is part of a broader recovery. \nA footnote was added to clarify that “exports include re-exports.” This is an important piece of information that was missing in the original description, and its inclusion ensures the viewer has a complete understanding of what is meant by “exports” and why it might be higher than imports.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry &lt;- country %&gt;%\n  mutate(Year = format(as.Date(Date), \"%Y\"))\n\n# Calculate total trade value for export, import, and re-export (from 2019 to 2024)\nsummary_data &lt;- country %&gt;%\n  filter(Type %in% c(\"Export\", \"Import\", \"Re-Export\"), Year %in% c(\"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\")) %&gt;%\n  mutate(Trade_Value = as.numeric(Trade_Value)) %&gt;%\n  mutate(Type = ifelse(Type == \"Re-Export\", \"Export\", Type)) %&gt;%\n  group_by(Year, Type) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  mutate(Total_Trade_Value_Billions = Total_Trade_Value / 1000,  # Convert to billions\n         Label = paste0(\"$\", round(Total_Trade_Value_Billions, 1))) \n\n# Calculate the total trade value for Export, Import, and Re-Export combined for each year\ntotal_trade_by_year &lt;- summary_data %&gt;%\n  group_by(Year) %&gt;%\n  summarise(Total_Trade_Value_Billions = sum(Total_Trade_Value_Billions, na.rm = TRUE))\n\n# Get the 2019 total trade value for calculating the 2020 percentage change\ntotal_trade_2019_value &lt;- total_trade_by_year$Total_Trade_Value_Billions[total_trade_by_year$Year == \"2019\"]\n\n# Calculate percentage change, keeping 2019 for reference\ntotal_trade_by_year &lt;- total_trade_by_year %&gt;%\n  mutate(Percentage_Change = (Total_Trade_Value_Billions / lag(Total_Trade_Value_Billions) - 1) * 100)\n\n# Manually compute the 2020 percentage change using 2019's value\ntotal_trade_by_year[total_trade_by_year$Year == \"2020\", \"Percentage_Change\"] &lt;- \n  (total_trade_by_year$Total_Trade_Value_Billions[total_trade_by_year$Year == \"2020\"] - total_trade_2019_value) / total_trade_2019_value * 100\n\n# Remove 2019 from the dataset to only plot 2020-2024\ntotal_trade_by_year &lt;- total_trade_by_year %&gt;%\n  filter(Year &gt;= 2020)\n\nsummary_data &lt;- summary_data %&gt;%\n  filter(Year &gt;= 2020)\n\nsummary_data$Year &lt;- as.integer(summary_data$Year)\ntotal_trade_by_year$Year &lt;- as.integer(total_trade_by_year$Year)\n\n# Define limits for both axes\nylim.prim &lt;- c(0, max(summary_data$Total_Trade_Value_Billions, na.rm = TRUE))\nylim.sec &lt;- c(-50, 25)\n\n# Transformation coefficients for scaling percentage change\nb &lt;- diff(ylim.prim) / diff(ylim.sec)\na &lt;- ylim.prim[1] - b * ylim.sec[1] \n\n\nggplot() +\n  # Bar chart for Total Trade Value in Billions\n  geom_bar(data = summary_data, aes(x = Year, y = Total_Trade_Value_Billions, fill = Type),\n           stat = \"identity\", position = \"dodge\") +\n  \n  # Line chart for Percentage Change, scaled appropriately\n  geom_line(data = total_trade_by_year, aes(x = Year, y = a + Percentage_Change * b), \n            color = \"#e79251\", size = 1) +\n  geom_point(data = total_trade_by_year, aes(x = Year, y = a + Percentage_Change * b), \n             color = \"#e79251\", size = 3) + \n  \n  # Add labels for the bar chart\n  geom_text(data = summary_data, aes(x = Year, y = 0, label = Label, group = Type),\n            position = position_dodge(width = 0.9), color= \"#737373\", vjust = -4, size = 5) +\n  \n  # Label the line chart with percentage values\n  geom_text(data = total_trade_by_year, aes(x = Year, y = a + Percentage_Change * b, \n                                             label = paste0(round(Percentage_Change, 1), \"%\")), \n            color = \"black\", vjust = -0.5, size = 5) +\n  \n  # Add a red dotted line at 0% percentage change\n  geom_hline(yintercept = a, color = \"#ff9c07\", linetype = \"dotted\", size = 1) +\n  \n  # Add total value labels on the line chart\n  geom_text(data = total_trade_by_year, aes(x = Year, y = a + Percentage_Change * b,\n                                             label = paste0(\"$\", round(Total_Trade_Value_Billions, 1), \" bil\")),\n            color = \"#004aad\", vjust = 1.5, size = 5) +\n  \n  # Set the primary Y-axis (Total Trade Value) and secondary Y-axis (Percentage Change)\n  scale_y_continuous(\n    name = \"Total Trade Value (in Billions)\",\n    sec.axis = sec_axis(~(. - a) / b, name = \"Percentage Change (%)\") \n  ) +\n  scale_x_continuous(\"Year\", breaks = 2020:2024) +\n  \n  # Customize the fill colors for Export and Import\n  scale_fill_manual(values = c(\"Export\" = \"#b4ceff\", \"Import\" = \"#cfe7af\")) +\n  \n  # Add title and axis labels\n  labs(\n    title = \"Annual Exports and Imports with Percentage Change in Total Trade Value (2020-2024)\",\n    x = \"Year\",\n    y = \"Total Trade Value (in Billions)\",\n    caption = \"*Note: Exports include Re-exports\",\n    subtitle = \"Line chart shows total trade value\"\n  ) +\n  theme_minimal() +\n  \n  # Adjust the size of the title and axis titles\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    axis.title.x = element_text(size = 16, face = \"bold\"),\n    axis.text.x = element_text(size = 12),\n    axis.title.y = element_text(size = 16, face = \"bold\"),\n    axis.text.y = element_text(size = 12),\n    plot.margin = margin(t = 20, r = 10, b = 10, l = 10)\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-2-bubble-chart-of-merchandise-trade-performance-with-major-trading-partners-2024",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-2-bubble-chart-of-merchandise-trade-performance-with-major-trading-partners-2024",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "5.2 Visualization 2: Bubble Chart of Merchandise Trade Performance with Major Trading Partners, 2024",
    "text": "5.2 Visualization 2: Bubble Chart of Merchandise Trade Performance with Major Trading Partners, 2024\n\n\n\n\n\nThis bubble chart provides a visual comparison of Singapore’s exports and imports with its major trading partners in 2024. The x-axis represents total export values, while the y-axis represents total import values for each country. The size of each bubble corresponds to the total trade value, with larger bubbles indicating higher overall trade volume. Each bubble is labeled with the respective country name and total trade value.\nA distinctive feature of this chart is its background, which is divided diagonally into two colors: blue and green. The blue section represents countries where Singapore’s exports exceed its imports, while the green section highlights countries where Singapore imports more than it exports.\n\n5.2.1 Pros and Cons\nPros:\n\nA clear distinction between trade surpluses and deficits is made using background colors, simplifying the identification of Singapore’s trade balance with each country.\nVarying bubble sizes effectively represent the scale of total trade with each country, enabling quick assessments of trading partners’ significance.\n\nCons:\n\nThe EU is represented as a single entity, making comparisons with individual countries difficult due to the aggregation of trade data from multiple member states.\nThe use of different bubble colors for each country does not carry any specific meaning, which can be misleading or add unnecessary complexity. \nThe chart displays total trade value but doesn’t show exact export and import values immediately, requiring further interaction to access detailed information.\n\n\n\n5.2.2 Makeover\nTo improve the visualization, several modifications have been made.\n\nThe top 10 trading countries have been selected instead of using the EU as a single entity. This allows for a more consistent comparison between individual countries.\nInstead of using background colors to distinguish trade surpluses and deficits, the bubble colors themselves now indicate whether Singapore exports more than it imports to the particular country (orange) or imports more than it exports (green). This change provides a clearer and more intuitive representation of the trade balance without relying on the background color.\nTooltip enhancements provide clearer data when hovering over a bubble. In addition to total trade value, the exact export and import values for each country are now displayed, making it easier to grasp the trade breakdown instantly.\n\n\nThe PlotThe Code\n\n\n\n\n\n\n\n\n\n\n\ncountry_2024 &lt;- country %&gt;%\n  filter(Year == 2024)\n\n# Summarize Import values\nimport_2024 &lt;- country_2024 %&gt;%\n  filter(Type == \"Import\") %&gt;%\n  group_by(Markets) %&gt;%\n  summarise(Total_Import_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Summarize Export values\nexport_2024 &lt;- country_2024 %&gt;%\n  filter(Type == \"Export\") %&gt;%\n  group_by(Markets) %&gt;%\n  summarise(Total_Export_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Summarize Re-Export values\nreexport_2024 &lt;- country_2024 %&gt;%\n  filter(Type == \"Re-Export\") %&gt;%\n  group_by(Markets) %&gt;%\n  summarise(Total_ReExport_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Merge all datasets into one\ntrade_2024 &lt;- import_2024 %&gt;%\n  full_join(export_2024, by = \"Markets\") %&gt;%\n  full_join(reexport_2024, by = \"Markets\") %&gt;%\n  mutate(Total_Export_Value = coalesce(Total_Export_Value, 0) + coalesce(Total_ReExport_Value, 0)) %&gt;%\n  select(Markets, Total_Import_Value, Total_Export_Value) \n\ntrade_2024 &lt;- trade_2024 %&gt;%\n  mutate(Total_Trade_Value = Total_Import_Value + Total_Export_Value)\n\n# Select top 10 markets by total trade value\ntop_10_markets &lt;- trade_2024 %&gt;%\n  arrange(desc(Total_Trade_Value)) %&gt;%\n  slice_head(n = 10)%&gt;%\n  mutate(Markets = ifelse(Markets == \"Korea, Rep Of\", \"South Korea\", Markets))\n\n\n# Create a new variable to color the bubbles\ntop_10_markets$BubbleColor &lt;- ifelse(top_10_markets$Total_Export_Value &gt; top_10_markets$Total_Import_Value, \"Imports from\nthat country exceeds\nexports to\nthat country\", \"Exports to\nthe country exceeds\nimports from\nthat country\")\n\n# Bubble plot\np &lt;- ggplot(top_10_markets, aes(y = Total_Import_Value / 1000, \n                                x = Total_Export_Value / 1000, \n                                size = Total_Trade_Value / 1000, \n                                label = Markets, \n                                text = paste(\"Total Export to\", Markets, \": S$\", round(Total_Export_Value / 1000, 1), \"Bil\",\n                                             \"\\nTotal Import from\",Markets, \": S$\", round(Total_Import_Value / 1000, 1), \"Bil\",\n                                             \"\\nTotal Trade Value : S$\", round(Total_Trade_Value / 1000, 1), \"Bil\"),\n                                fill = BubbleColor)) +\n  \n  # Bubbles\n  geom_point(alpha = 0.7, shape = 21, color = \"black\") +  \n  geom_text(vjust = -1, size = 3) +  \n  \n  scale_fill_manual(values = c(\"Imports from\nthat country exceeds\nexports to\nthat country\" = \"#9cc567\", \"Exports to\nthe country exceeds\nimports from\nthat country\" = \"#e79251\")) +  # Define colors\n  scale_size_continuous(range = c(5, 30), \n                        name = \"Total Trade Value (Billion $)\", \n                        breaks = c(50, 100, 150), \n                        labels = c(\"50\", \"100\", \"150\")) +  \n  scale_x_continuous(limits = c(0, 100), \n                     breaks = seq(0, 100, by = 10), \n                     labels = paste(seq(0, 100, by = 10))) + \n  scale_y_continuous(limits = c(0, 100), \n                     breaks = seq(0, 100, by = 10), \n                     labels = paste(seq(0, 100, by = 10))) + \n  \n  # Title and axis labels\n  labs(title = \"Top 10 Merchandise Trade Markets (2024)\", \n       y = \"Total Import Value (Billion $)\", \n       x = \"Total Export Value (Billion $)\") +   \n  theme_minimal() +\n  \n  # Removing legend\n  guides(size = guide_none(), color = guide_none()) \n\n# Interactivity-Show Trade value on hover\nggplotly(p, tooltip = \"text\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-3",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualization-3",
    "title": "Take-home Exercise 02: Be Tradewise or Otherwise",
    "section": "5.3 Visualization 3:",
    "text": "5.3 Visualization 3:\n\n5.3.1 Pros and Cons\n\n\n5.3.2 Makeover"
  }
]